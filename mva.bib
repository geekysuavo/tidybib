@article{
   title = {IEEE Standard for Floating-Point Arithmetic},
   journal = {IEEE Std 754-2008},
   pages = {1-58},
   keywords = {IEEE standards
floating point arithmetic
programming
IEEE standard
arithmetic formats
computer programming
decimal floating-point arithmetic},
   year = {2008}
}

@article{
   author = {Anderson, Paul E. and Mahle, Deirdre A. and Doom, Travis E. and Reo, Nicholas V. and Del, Raso Nicholas J. and Raymer, Michael L.},
   title = {Dynamic adaptive binning: an improved quantification technique for NMR spectroscopic data},
   journal = {Metabolomics},
   volume = {7},
   number = {2},
   pages = {179-190},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:635605(Journal; Online Computer File)
10.1007/s11306-010-0242-7},
   abstract = {The interpretation of NMR exptl. results for metabolomics studies requires intensive signal processing and multivariate data anal. techniques. A key step in this process is the quantification of spectral features, which is commonly accomplished by dividing an NMR spectrum into several hundred integral regions or bins. Binning attempts to minimize effects from variations in peak positions caused by sample pH, ionic strength, and compn., while reducing the dimensionality for multivariate statistical analyses. Herein we develop an improved novel spectral quantification technique, dynamic adaptive binning. With this technique, bin boundaries are detd. by optimizing an objective function using a dynamic programming strategy. The objective function measures the quality of a bin configuration based on the no. of peaks per bin. This technique shows a significant improvement over both traditional uniform binning and other adaptive binning techniques. This improvement is quantified via synthetic validation sets by analyzing an algorithm's ability to create bins that do not contain more than a single peak and that maximize the distance from peak to bin boundary. The validation sets are developed by characterizing the salient distributions in exptl. NMR spectroscopic data. Further, dynamic adaptive binning is applied to a 1H NMR-based expt. to monitor rat urinary metabolites to empirically demonstrate improved spectral quantification. [on SciFinder(R)]},
   keywords = {dynamic adaptive binning NMR spectroscopy},
   year = {2011}
}

@article{
   author = {Anderson, P. E. and Reo, N. V. and DelRaso, N. J. and Doom, T. E. and Raymer, M. L.},
   title = {Gaussian binning: a new kernel-based method for processing NMR spectroscopic data for metabolomics},
   journal = {Metabolomics},
   volume = {4},
   number = {3},
   pages = {261-272},
   note = {345PE
Times Cited:12
Cited References Count:27},
   abstract = {In many metabolomics studies, NMR spectra are divided into bins of fixed width. This spectral quantification technique, known as uniform binning, is used to reduce the number of variables for pattern recognition techniques and to mitigate effects from variations in peak positions; however, shifts in peaks near the boundaries can cause dramatic quantitative changes in adjacent bins due to non-overlapping boundaries. Here we describe a new Gaussian binning method that incorporates overlapping bins to minimize these effects. A Gaussian kernel weights the signal contribution relative to distance from bin center, and the overlap between bins is controlled by the kernel standard deviation. Sensitivity to peak shift was assessed for a series of test spectra where the offset frequency was incremented in 0.5 Hz steps. For a 4 Hz shift within a bin width of 24 Hz, the error for uniform binning increased by 150%, while the error for Gaussian binning increased by 50%. Further, using a urinary metabolomics data set (from a toxicity study) and principal component analysis (PCA), we showed that the information content in the quantified features was equivalent for Gaussian and uniform binning methods. The separation between groups in the PCA scores plot, measured by the J(2) quality metric, is as good or better for Gaussian binning versus uniform binning. The Gaussian method is shown to be robust in regards to peak shift, while still retaining the information needed by classification and multivariate statistical techniques for NMR-metabolomics data.},
   keywords = {gaussian
binning
pattern recognition
quantification
nuclear magnetic resonance
pattern-recognition classification
magnetic-resonance spectroscopy
h-1-nmr spectroscopy
principal-components
rat
urine
model
metabonomics
lesions
liver},
   year = {2008}
}

@article{
   author = {Anderssen, E. and Dyrstad, K. and Westad, F. and Martens, H.},
   title = {Reducing over-optimism in variable selection by cross-model validation},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {84},
   number = {1-2},
   pages = {69-74},
   note = {115XX
Times Cited:48
Cited References Count:19},
   abstract = {Extensive optimisation of a mathematical model's fit to a relatively small set of empirical data, may lead to over-optimistic validation results. If the assessment of the final, optimised model is based on the same validation method and the same input data that were used as basis for the extensive model optimisation, accumulated spurious correlations may appear as real predictive ability in the final model validation. An example of this is the use of extensive variable selection in multiple regression, based on a cross-model validation scheme.
To illustrate the over-optimism problem in optimisation based on conventional one-layered validation, an artificial data set, with only random numbers was submitted to regression modelling. The model was optimised by stepwise variable selection. A very good apparent predictive ability for y from X was found in the final model by leave-one-out cross-validation (84%), after the number of X-variables had been reduced stepwise from 500 to 29. Finally, the performance of the cross-model validation is tested on one large QSAR data set. Several calibration sets were chosen randomly and a regression model optimised by variable selection. The prediction accuracy of these models was compared to the cross-validation and cross-model validation results. In these tests cross-model validation gives the better measure of model predictive ability. (c) 2006 Published by Elsevier B.V.},
   keywords = {variable selection
regression
over-fitting
cross-model validation
jack-knifing
qsar
gmp phosphodiesterase inhibitors
regression
discovery},
   year = {2006}
}

@article{
   author = {Baker, Monya},
   title = {Metabolomics: From small molecules to big ideas},
   journal = {Nat. Methods},
   volume = {8},
   number = {2},
   pages = {117-121},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:129548(Journal; General Review; Online Computer File)
10.1038/nmeth0211-117},
   abstract = {A review. The focus of metabolomic studies is shifting from cataloging chem. structures to finding biol. stories. [on SciFinder(R)]},
   keywords = {review metabolomics},
   year = {2011}
}

@article{
   author = {Barker, M. and Rayens, W.},
   title = {Partial least squares for discrimination},
   journal = {Journal of Chemometrics},
   volume = {17},
   number = {3},
   pages = {166-173},
   note = {663KY
Times Cited:354
Cited References Count:30},
   abstract = {Partial least squares (PLS) was not originally designed as a tool for statistical discrimination. In spite of this, applied scientists routinely use PLS for classification and there is substantial empirical evidence to suggest that it performs well in that role. The interesting question is: why can a procedure that is principally designed for overdetermined regression problems locate and emphasize group structure? Using PLS in this manner has heurestic support owing to the relationship between PLS and canonical correlation analysis (CCA) and the relationship, in turn, between CCA and linear discriminant analysis (LDA). This paper replaces the heuristics with a formal statistical explanation. As a consequence, it will become clear that PLS is to be preferred over PCA when discrimination is the goal and dimension reduction is needed. Copyright (C) 2003 John Wiley Sons, Ltd.},
   keywords = {partial least squares
linear discrimination
dimension reduction
pattern-recognition
regression
chemometrics
components},
   year = {2003}
}

@article{
   author = {Beckonert, Olaf and Keun, Hector C. and Ebbels, Timothy M. D. and Bundy, Jacob and Holmes, Elaine and Lindon, John C. and Nicholson, Jeremy K.},
   title = {Metabolic profiling, metabolomic and metabonomic procedures for NMR spectroscopy of urine, plasma, serum and tissue extracts},
   journal = {Nat. Protocols},
   volume = {2},
   number = {11},
   pages = {2692-2703},
   note = {10.1038/nprot.2007.376},
   year = {2007}
}

@article{
   author = {Beneduci, A. and Chidichimo, G. and Dardo, G. and Pontoni, G.},
   title = {Highly routinely reproducible alignment of H-1 NMR spectral peaks of metabolites in huge sets of urines},
   journal = {Analytica Chimica Acta},
   volume = {685},
   number = {2},
   pages = {186-195},
   note = {716GC
Times Cited:0
Cited References Count:24},
   abstract = {A method to obtain high reproducibility of H-1 NMR chemical shift of peaks of biofluid metabolites, by simple acidification with HCl is evaluated. Biofluid H-1 NMR analysis is indeed spoiled by a strong chemical shift dependence of metabolite peaks on parameters such as ionic strength, concentration of some earth alkali cations and, mostly, on pH of samples. The resulting chemical shift variations, as large as 0.1 ppm, generate misalignments of homogeneous peaks, artifacts and misinterpretations. Reproducible alignment is essential in H-1 NMR based metabonomics, where peak misalignments prevent even very wide bins (i.e., 0.04 ppm, as elsewhere proposed) from being used to integrate spectral data for multivariate statistical analysis. Here is demonstrated that routine acidification with HCl to 1.2 <= pH <= 2.0 ensures highly reproducible peak alignment of urine H-1 NMR spectra. In this respect, simple inspection of citrate peaks in the urine can be used to measure pH, as it will be extensively discussed, in that at such low pH they show no dependency on other urine components as reported at higher pH. Under these conditions, in as many as 493 urine samples, in which concentrations of Ca2+, Mg2+, K+, Na+, Cl-, phosphate, and creatinine and ionic strength measured by means of well standardized conventional procedures, showed very wide ranges, peaks align within a SD always lower than 0.002 ppm, thus allowing the use of integration bins at least five times narrower than 0.04 ppm. (C) 2010 Elsevier B.V. All rights reserved.},
   keywords = {h-1 nmr
urine metabolite
metabonomics
peak alignment
ph
inorganic composition
magnetic-resonance
biological-fluids
inborn-errors
metabonomics
spectroscopy
metabolomics},
   year = {2011}
}

@article{
   author = {Bras, L. P. and Bernardino, S. A. and Lopes, J. A. and Menezes, J. C.},
   title = {Multiblock PLS as an approach to compare and combine NIR and MIR spectra in calibrations of soybean flour},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {75},
   number = {1},
   pages = {91-99},
   note = {888RF
Times Cited:33
Cited References Count:28},
   abstract = {The present work is aimed at investigating the potential benefits of simultaneously combining near-infrared (NIR) and mid-infrared (MIR) spectral regions for use in calibration development of soybean flour quality properties (crude protein and moisture). NIR and MIR spectra were analysed separately using single partial least squares (PLS), and then both spectral data sets were utilized together in the modelling by applying two multiblock inethodologies based on PLS regression: Multiblock PLS (MB-PLS) and Serial PLS (S-PLS). Utilizing the concept of net analyte signal (NAS), models constructed from NIR or MIR data were compared in terms of analytical figures of merit (sensitivity (SEN), selectivity (SEL) and limit of detection (LOD)).
When utilized alone, the MIR spectra gave models with considerably inferior prediction power and analytical figures of merit than NIR-based models. The multiblock methodology revealed to be very useful, since it helped to determine if there was distinctive information in each spectral data set and evaluate the relative importance of each data set. The results pointed out the existence of additional information in the MIR spectra not present in the NIR spectra. Although several works have already been reported comparing NIR and MIR spectroscopic techniques using different multivariate regression techniques, at the best of our knowledge none of them applied the approach of multiblock PLS. Therefore, the present work intends to explore this direction, using the NIR and MIR spectra as predictor blocks to model flour's properties in a parallel mode (MB-PLS) or in a serial mode (S-PLS). (C) 2004 Elsevier B.V. All rights reserved.},
   keywords = {multiblock pls
near-infrared spectroscopy
mid-infrared spectroscopy
complex natural raw materials
soybean flour
net analyte signal
multivariate calibration
figures
models
merit},
   year = {2005}
}

@article{
   author = {Bro, R.},
   title = {PARAFAC. Tutorial and applications},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {38},
   number = {2},
   pages = {149-171},
   note = {Yh196
Times Cited:796
Cited References Count:60},
   abstract = {This paper explains the multi-way decomposition method PARAFAC and its use in chemometrics. PARAFAC is a generalization of PCA to higher order arrays, but some of the characteristics of the method are quite different from the ordinary two-way case. There is no rotation problem in PARAFAC, and e.g., pure spectra can be recovered from multi-way spectral data. One cannot as in PCA estimate components successively as this will give a model with poorer fit, than if the simultaneous solution is estimated. Finally scaling and centering is not as straightforward in the multi-way case as in the two-way case. An important advantage of using multi-way methods instead of unfolding methods is that the estimated models are very simple in a mathematical sense, and therefore more robust and easier to interpret. All these aspects plus more are explained in this tutorial and an implementation in Matlab code is available, that contains most of the features explained in the text. Three examples show how PARAFAC can be used for specific problems. The applications include subjects as: Analysis of variance by PARAFAC, a five-way application of PARAFAC, PARAFAC with half the elements missing, PARAFAC constrained to positive solutions and PARAFAC for regression as in principal component regression.},
   keywords = {least-squares algorithm
3-way arrays
fluorescence spectroscopy
individual-differences
linear constraints
decomposition
models
rank
calibration
resolution},
   year = {1997}
}

@article{
   author = {Broadhurst, D. I. and Kell, D. B.},
   title = {Statistical strategies for avoiding false discoveries in metabolomics and related experiments},
   journal = {Metabolomics},
   volume = {2},
   number = {4},
   pages = {171-196},
   note = {151AV
Times Cited:120
Cited References Count:245},
   abstract = {Many metabolomics, and other high-content or high-throughput, experiments are set up such that the primary aim is the discovery of biomarker metabolites that can discriminate, with a certain level of certainty, between nominally matched 'case' and 'control' samples. However, it is unfortunately very easy to find markers that are apparently persuasive but that are in fact entirely spurious, and there are well-known examples in the proteomics literature. The main types of danger are not entirely independent of each other, but include bias, inadequate sample size (especially relative to the number of metabolite variables and to the required statistical power to prove that a biomarker is discriminant), excessive false discovery rate due to multiple hypothesis testing, inappropriate choice of particular numerical methods, and overfitting (generally caused by the failure to perform adequate validation and cross-validation). Many studies fail to take these into account, and thereby fail to discover anything of true significance (despite their claims). We summarise these problems, and provide pointers to a substantial existing literature that should assist in the improved design and evaluation of metabolomics experiments, thereby allowing robust scientific conclusions to be drawn from the available data. We provide a list of some of the simpler checks that might improve one's confidence that a candidate biomarker is not simply a statistical artefact, and suggest a series of preferred tests and visualisation tools that can assist readers and authors in assessing papers. These tools can be applied to individual metabolites by using multiple univariate tests performed in parallel across all metabolite peaks. They may also be applied to the validation of multivariate models. We stress in particular that classical p-values such as "p < 0.05", that are often used in biomedicine, are far too optimistic when multiple tests are done simultaneously (as in metabolomics). Ultimately it is desirable that all data and metadata are available electronically, as this allows the entire community to assess conclusions drawn from them. These analyses apply to all high-dimensional 'omics' datasets.},
   keywords = {statistics
machine learning
false discovery
receiver-operator characteristic
hypothesis testing
statistical power
bonferroni correction
bias
overfitting
cross validiation
credit assignment
visualisation
coronary-artery-disease
genetic algorithms
systems biology
pattern-recognition
functional genomics
variable selection
mass-spectrometry
microarray data
breast-cancer
roc curves},
   year = {2006}
}

@article{
   author = {Bundy, Jacob G. and Davey, Matthew P. and Viant, Mark R.},
   title = {Environmental metabolomics: a critical review and future perspectives},
   journal = {Metabolomics},
   volume = {5},
   number = {1},
   pages = {3-21},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2009:250617(Journal)
10.1007/s11306-008-0152-0},
   abstract = {Environmental metabolomics is the application of metabolomics to characterize the interactions of organisms with their environment. This approach has many advantages for studying organism-environment interactions and for assessing organism function and health at the mol. level. As such, metabolomics is finding an increasing no. of applications in the environmental sciences, ranging from understanding organismal responses to abiotic pressures, to investigating the responses of organisms to other biota. These interactions can be studied from individuals to populations, which can be related to the traditional fields of ecophysiol. and ecol., and from instantaneous effects to those over evolutionary time scales, the latter enabling studies of genetic adaptation. This review provides a comprehensive and current overview of environmental metabolomics research. We begin with an overview of metabolomic studies into the effects of abiotic pressures on organisms. In the field of ecophysiol., studies on the metabolic responses to temp., water, food availability, light and circadian rhythms, atm. gases and season are reviewed. A section on ecotoxicogenomics discusses research in aquatic and terrestrial ecotoxicol., assessing organismal responses to anthropogenic pollutants in both the lab. and field. We then discuss environmental metabolomic studies of diseases and biotic-biotic interactions, in particular herbivory. Finally, we critically evaluate the contribution that metabolomics has made to the environmental sciences, and highlight and discuss recommendations to advance our understanding of the environment, ecol. and evolution using a metabolomics approach. [on SciFinder(R)]},
   year = {2009}
}

@article{
   author = {Bylesjo, M. and Rantalainen, M. and Cloarec, O. and Nicholson, J. K. and Holmes, E. and Trygg, J.},
   title = {OPLS discriminant analysis: combining the strengths of PLS-DA and SIMCA classification},
   journal = {Journal of Chemometrics},
   volume = {20},
   number = {8-10},
   pages = {341-351},
   note = {175ND
Times Cited:150
Cited References Count:26},
   abstract = {The characteristics of the OPLS method have been investigated for the purpose of discriminant analysis (OPLS-DA). We demonstrate how class-orthogonal variation can be exploited to augment classification performance in cases where the individual classes exhibit divergence in within-class variation, in analogy with soft independent modelling of class analogy (SIMCA) classification. The prediction results will be largely equivalent to traditional supervised classification using PLS-DA if no such variation is present in the classes. A discriminatory strategy is thus outlined, combining the strengths of PLS-DA and SIMCA classification within the framework of the OPLS-DA method. Furthermore, resampling methods have been employed to generate distributions of predicted classification results and subsequently assess classification belief. This enables utilisation of the class-orthogonal variation in a proper statistical context. The proposed decision rule is compared to common decision rules and is shown to produce comparable or less class-biased classification results. Copyright (c) 2007 John Wiley & Sons, Ltd.},
   keywords = {opls-da
orthogonal
multivariate
classification
pls-da
simca
orthogonal signal correction
gene-expression data
multivariate calibration
data sets
prediction
identification
validation
spectra
models},
   year = {2006}
}

@article{
   author = {Cherney, D. P. and Ekman, D. R. and Dix, D. J. and Collette, T. W.},
   title = {Raman spectroscopy-based metabolomics for differentiating exposures to triazole fungicides using rat urine},
   journal = {Analytical Chemistry},
   volume = {79},
   number = {19},
   pages = {7324-7332},
   note = {216IF
Times Cited:4
Cited References Count:38},
   abstract = {Normal Raman spectroscopy was evaluated as a metabolomic tool for assessing the impacts of exposure to environmental contaminants, using rat urine collected during the course of a toxicological study. Specifically, one of three triazole fungicides, myclobutanil, propiconazole, or triadimefon, was administered daily via oral gavage to male Sprague-Dawley rats at doses of 300, 300, or 175 mg/kg, respectively. Urine was collected from all three treatment groups and also from vehicle control rats on day six, following five consecutive days of exposure. Spectra were acquired with a CCD-based dispersive Raman spectrometer, using 785-nm diode laser excitation. To optimize the signal-to-noise ratio, urine samples were filtered through a stirred ultrafiltration cell with a 500 nominal molecular weight limit filter to remove large, unwanted urine components that can degrade the spectrum via fluorescence. However, a subsequent investigation suggested that suitable spectra can be obtained in a high-throughput fashion, with little or no Raman-specific sample preparation. For the sake of comparison, a parallel H-1 NMR-based metabolomic analysis was also conducted on the unfiltered samples. Results from multivariate data analysis demonstrated that the Raman method compares favorably with NMR in regard to the ability to differentiate responses from these three contaminants.},
   keywords = {conazole fungicides
creatinine measurement
quantitative-analysis
nmr-spectroscopy
drug toxicity
blood-plasma
myclobutanil
metabonomics
triadimefon
profiles},
   year = {2007}
}

@article{
   author = {Cloarec, O. and Dumas, M. E. and Craig, A. and Barton, R. H. and Trygg, J. and Hudson, J. and Blancher, C. and Gauguier, D. and Lindon, J. C. and Holmes, E. and Nicholson, J.},
   title = {Statistical total correlation spectroscopy: An exploratory approach for latent biomarker identification from metabolic H-1 NMR data sets},
   journal = {Analytical Chemistry},
   volume = {77},
   number = {5},
   pages = {1282-1289},
   note = {903FA
Times Cited:257
Cited References Count:22},
   abstract = {We describe here the implementation of the statistical total correlation spectroscopy (STOCSY) analysis method for aiding the identification of potential biomarker molecules in metabonomic studies based on NMR spectroscopic data. STOCSY takes advantage of the multicollinearity of the intensity variables in a set of spectra (in this case H-1 NMR spectra) to generate a pseudo-two-dimensional NMR spectrum that displays the correlation among the intensities of the various peaks across the whole sample. This method is not limited to the usual connectivities that are deducible from more standard two-dimensional NMR spectroscopic methods, such as TOCSY. Moreover, two or more molecules involved in the same pathway can also present high intermolecular correlations because of biological covariance or can even be anticorrelated. This combination of STOCSY with supervised pattern recognition and particularly orthogonal projection on latent structure-discriminant analysis (O-PLS-DA) offers a new powerful framework for analysis of metabonomic data. In a first step O-PLS-DA extracts the part of NMR spectra related to discrimination. This information is then cross-combined with the STOCSY results to help identify the molecules responsible for the metabolic variation. To illustrate the applicability of the method, it has been applied to 114 NMR spectra of urine from a metabonomic study of a model of insulin resistance based on the administration of a carbohydrate diet to three different mice strains (C57BL/60xjr, BAIB/cOxjr, and 129S6/SvEvOxjr) in which a series of metabolites of biological importance can be conclusively assigned and identified by use of the STOCSY approach.},
   keywords = {automatic data reduction
nmr-spectra
metabonomics
urine
disease
o2-pls
h-1},
   year = {2005}
}

@article{
   author = {Cloarec, O. and Dumas, M. E. and Trygg, J. and Craig, A. and Barton, R. H. and Lindon, J. C. and Nicholson, J. K. and Holmes, E.},
   title = {Evaluation of the orthogonal projection on latent structure model limitations caused by chemical shift variability and improved visualization of biomarker changes in H-1 NMR spectroscopic metabonomic studies},
   journal = {Analytical Chemistry},
   volume = {77},
   number = {2},
   pages = {517-526},
   note = {887PP
Times Cited:195
Cited References Count:17},
   abstract = {In general, applications of metabonomics using biofluid NMR spectroscopic analysis for probing abnormal biochemical profiles in disease or due to toxicity have all relied on the use of chemometric techniques for sample classification. However, the well-known variability of some chemical shifts in H-1 NMR spectra of biofluids due to environmental differences such as pH variation, when coupled with the large number of variables in such spectra, has led to the situation where it is necessary to reduce the size of the spectra or to attempt to align the shifting peaks, to get more robust and interpretable chemometric models. Here, a new approach that avoids this problem is demonstrated and shows that, moreover, inclusion of variable peak position data can be beneficial and can lead to useful biochemical information. The interpretation of chemometric models using combined back-scaled loading plots and variable weights demonstrates that this peak position variation can be handled successfully and also often provides additional information on the physicochemical variations in metabonomic data sets.},
   keywords = {peak alignment
nmr signals
reduction
urine},
   year = {2005}
}

@article{
   author = {Cortes, C. and Vapnik, V.},
   title = {Support-Vector Networks},
   journal = {Machine Learning},
   volume = {20},
   number = {3},
   pages = {273-297},
   note = {Rx354
Times Cited:3822
Cited References Count:14},
   abstract = {The support-vector network is a new learning machine for two-group classification problems. The machine conceptually implements the following idea: input vectors are non-linearly mapped to a very high-dimension feature space. In this feature space a linear decision surface is constructed. Special properties of the decision surface ensures high generalization ability of the learning machine. The idea behind the support-vector network was previously implemented for the restricted case where the training data can be separated without errors. We here extend this result to non-separable training data.
High generalization ability of support-vector networks utilizing polynomial input transformations is demonstrated. We also compare the performance of the support-vector network to various classical learning algorithms that all took part in a benchmark study of Optical Character Recognition.},
   keywords = {pattern recognition
efficient learning algorithms
neural networks
radial basis function classifiers
polynomial classifiers},
   year = {1995}
}

@article{
   author = {Craig, A. and Cloareo, O. and Holmes, E. and Nicholson, J. K. and Lindon, J. C.},
   title = {Scaling and normalization effects in NMR spectroscopic metabonomic data sets},
   journal = {Analytical Chemistry},
   volume = {78},
   number = {7},
   pages = {2262-2267},
   note = {031EJ
Times Cited:99
Cited References Count:30},
   abstract = {Considerable confusion appears to exist in the metabonomics literature as to the real need for, and the role of, preprocessing the acquired spectroscopic data. A number of studies have presented various data manipulation approaches, some suggesting an optimum method. In metabonomics, data are usually presented as a table where each row relates to a given sample or analytical experiment and each column corresponds to a single measurement in that experiment, typically individual spectral peak intensities or metabolite concentrations. Here we suggest definitions for and discuss the operations usually termed normalization (a table row operation) and scaling (a table column operation) and demonstrate their need in H-1 NMR spectroscopic data sets derived from urine. The problems associated with "binned" data (i.e., values integrated over discrete spectral regions) are also discussed, and the particular biological context problems of analytical data on urine are highlighted. It is shown that care must be exercised in calculation of correlation coefficients for data sets where normalization to a constant sum is used. Analogous considerations will be needed for other biofluids, other analytical approaches (e.g., HPLC-MS), and indeed for other "omics" techniques (i.e., transcriptomics or proteomics) and for integrated studies with "fused" data sets. It is concluded that data preprocessing is context dependent and there can be no single method for general use.},
   keywords = {pattern-recognition methods
magnetic-resonance spectra
classification
metabolomics
urine
identification
reduction
alignment
model
peaks},
   year = {2006}
}

@article{
   author = {Csenki, Leonard and Alm, Erik and Torgrip, Ralf J. O. and Aaberg, K. Magnus and Nord, Lars I. and Schuppe-Koistinen, Ina and Lindberg, Johan},
   title = {Proof of principle of a generalized fuzzy Hough transform approach to peak alignment of one-dimensional 1H NMR data},
   journal = {Anal. Bioanal. Chem.},
   volume = {389},
   number = {3},
   pages = {875-885},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2007:1075683(Journal)
10.1007/s00216-007-1475-9},
   abstract = {In metabolic profiling, multivariate data anal. techniques are used to interpret one-dimensional (1D) 1H NMR data. Multivariate data anal. techniques require that peaks are characterized by the same variables in every spectrum. This location constraint is essential for correct comparison of the intensities of several NMR spectra. However, variations in physicochem. factors can cause the locations of the peaks to shift. The location prerequisite may thus not be met, and so, to solve this problem, alignment methods have been developed. However, current state-of-the-art algorithms for data alignment cannot resolve the inherent problems encountered when analyzing NMR data of biol. origin, because they are unable to align peaks when the spatial order of the peaks changes - a commonly occurring phenomenon. In this paper a new algorithm is proposed, based on the Hough transform operating on an image representation of the NMR dataset that is capable of correctly aligning peaks when existing methods fail. The proposed algorithm was compared with current state-of-the-art algorithms operating on a selected plasma dataset to demonstrate its potential. A urine dataset was also processed using the algorithm as a further demonstration. The method is capable of successfully aligning the plasma data but further development is needed to address more challenging applications, for example urine data. [on SciFinder(R)]},
   keywords = {fuzzy Hough transform peak alignment one dimensional NMR},
   year = {2007}
}

@article{
   author = {Davis, Richard A. and Charlton, Adrian J. and Godward, John and Jones, Stephen A. and Harrison, Mark and Wilson, Julie C.},
   title = {Adaptive binning: An improved binning method for metabolomics data using the undecimated wavelet transform},
   journal = {Chemom. Intell. Lab. Syst.},
   volume = {85},
   number = {1},
   pages = {144-154},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2007:4478(Journal)
10.1016/j.chemolab.2006.08.014},
   abstract = {Statistical anal. of metabolomic datasets can lead to erroneous interpretation of results due to misalignment of the data. Therefore pre-processing methods for peak alignment and data averaging (binning or bucketing) to improve data quality have been used. Here we introduce adaptive binning. The undecimated wavelet transform is used in an improved method for correcting variation in chem. shifts in NMR spectroscopy data. Adaptive binning using theor. and metabolomics NMR spectra significantly increases the ratio of inter-class to intra-class variation and increases data interpretability when compared to conventional binning. [on SciFinder(R)]},
   year = {2007}
}

@article{
   author = {De Meyer, Tim and Sinnaeve, Davy and Van Gasse, Bjorn and Tsiporkova, Elena and Rietzschel, Ernst R. and De Buyzere, Marc L. and Gillebert, Thierry C. and Bekaert, Sofie and Martins, Jose C. and Van Criekinge, Wim},
   title = {NMR-Based Characterization of Metabolic Alterations in Hypertension Using an Adaptive, Intelligent Binning Algorithm},
   journal = {Anal. Chem.},
   volume = {80},
   number = {10},
   pages = {3783-3790},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2008:486381(Journal)
10.1021/ac7025964},
   abstract = {As with every -omics technol., metabolomics requires new methodologies for data processing. Due to the large spectral size, a std. approach in NMR-based metabolomics implies the division of spectra into equally sized bins, thereby simplifying subsequent data anal. Yet, disadvantages are the loss of information and the occurrence of artifacts caused by peak shifts. Here, a new binning algorithm, Adaptive Intelligent Binning (AI-Binning), which largely circumvents these problems, is presented. AI-Binning recursively identifies bin edges in existing bins, requires only minimal user input, and avoids the use of arbitrary parameters or ref. spectra. The performance of AI-Binning is demonstrated using serum spectra from 40 hypertensive and 40 matched normotensive subjects from the Asklepios study. Hypertension is a major cardiovascular risk factor characterized by a complex biochem. and, in most cases, an unknown origin. The binning algorithm resulted in an improved classification of hypertensive status compared with that of std. binning and facilitated the identification of relevant metabolites. Moreover, since the occurrence of noise variables is largely avoided, AI-Binned spectra can be unit-variance scaled. This enables the detection of relevant, low-intensity metabolites. These results demonstrate the power of AI-Binning and suggest the involvement of α-1 acid glycoproteins and choline biochem. in hypertension. [on SciFinder(R)]},
   keywords = {NMR metabolic alteration hypertension Adaptive Intelligent Binning algorithm},
   year = {2008}
}

@article{
   author = {Dettmer, K. and Aronov, P. A. and Hammock, B. D.},
   title = {Mass spectrometry-based metabolomics},
   journal = {Mass Spectrometry Reviews},
   volume = {26},
   number = {1},
   pages = {51-78},
   note = {120UY
Times Cited:331
Cited References Count:144},
   abstract = {This review presents an overview of the dynamically developing field of mass spectrometry-based metabolomics. Metabolomics aims at the comprehensive and quantitative analysis of wide arrays of metabolites in biological samples. These numerous analytes have very diverse physico-chemical properties and occur at different abundance levels. Consequently, comprehensive metabolomics investigations are primarily a challenge for analytical chemistry and specifically mass spectrometry has vast potential as a tool for this type of investigation. Metabolomics require special approaches for sample preparation, separation, and mass spectrometric analysis. Current examples of those approaches are described in this review. It primarily focuses on metabolic fingerprinting, a technique that analyzes all detectable analytes in a given sample with subsequent classification of samples and identification of differentially expressed metabolites, which define the sample classes. To perform this complex task, data analysis tools, metabolite libraries, and databases are required. Therefore, recent advances in metabolomics bioinformatics are also discussed. (c) 2006 Wiley Periodicals, Inc.},
   keywords = {metabolomics
metabolic fingerprinting
metabolic profiling
lipidomics
mass spectrometry
liquid chromatography/mass spectrometry
transform infrared-spectroscopy
volatile secondary metabolites
gas-chromatography
high-throughput
intracellular metabolites
quantitative-analysis
functional genomics
spectral libraries
biological samples},
   year = {2007}
}

@article{
   author = {Dixon, S. J. and Heinrich, N. and Holmboe, M. and Schaefer, M. L. and Reed, R. R. and Trevejo, J. and Brereton, R. G.},
   title = {Use of cluster separation indices and the influence of outliers: application of two new separation indices, the modified silhouette index and the overlap coefficient to simulated data and mouse urine metabolomic profiles},
   journal = {Journal of Chemometrics},
   volume = {23},
   number = {1-2},
   pages = {19-31},
   note = {416WY
Times Cited:8
Cited References Count:23},
   abstract = {To quantify separate classes, four indices are compared namely the Davies Bouldin index, the silhouette width and two new approaches described in this paper, the modified silhouette width index based on the proportion of objects with a positive silhouette width and the Overlap Coefficient. Four sets of simulated datasets are described, each in turn, consisting of 15 sets of data of varying degrees of overlap, and differing in the nature of outliers. Three experimental datasets consisting of the gas chromatography mass spectrometry of extracts from mouse urine obtained to study the effect of different environmental (stress), physiological (diet) and developmental (age) factors on their metabolic profiles are also described. The paper discusses the robustness of each approach to outliers, and to allow assessment of class separation for each index. The two modifications protect against outliers. Copyright (C) 2008 John Wiley & Sons, Ltd.},
   keywords = {cluster separation
davies bouldin index
silhouette index
outliers
metabolomics
simulations
urine
covariance determinant estimator
mass-spectrometry
tests
robustness
volatiles
sweat},
   year = {2009}
}

@article{
   author = {Dunn, W. B. and Ellis, D. I.},
   title = {Metabolomics: Current analytical platforms and methodologies},
   journal = {Trac-Trends in Analytical Chemistry},
   volume = {24},
   number = {4},
   pages = {285-294},
   note = {917ZD
Times Cited:267
Cited References Count:94},
   abstract = {During the previous decade, a new array of analytical methodologies and technologies were introduced related to the analysis of microbial, plant and animal metabolomes (complete collections of all low molecular weight compounds in a cell). The scientific field of metabolomics was born. In this review, we discuss advances in methodologies and technologies, and outline applications. (c) 2005 Elsevier Ltd. All rights reserved.},
   keywords = {infrared spectroscopy
mass spectrometry
nuclear magnetic resonance spectroscopy
metabolic fingerprinting
metabolic profiling
metabolite
metabolome
metabolomics
metabonomics
transform infrared-spectroscopy
chromatography-mass-spectrometry
solid-phase microextraction
h-1-nmr spectroscopy
functional genomics
ft-ir
multivariate-analysis
raman-spectroscopy
electrospray-ionization
arabidopsis-thaliana},
   year = {2005}
}

@article{
   author = {Eliasson, Mattias and Raennar, Stefan and Trygg, Johan},
   title = {From data processing to multivariate validation - essential steps in extracting interpretable information from metabolomics data},
   journal = {Curr. Pharm. Biotechnol.},
   volume = {12},
   number = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.},
   pages = {996-1004},
   note = {CAPLUS AN 2011:1241492(Journal; General Review)},
   abstract = {A review. In metabolomics studies there is a clear increase of data. This indicates the necessity of both having a battery of suitable anal. methods and validation procedures able to handle large amts. of data. In this review, an overview of the metabolomics data processing pipeline is presented. A selection of recently developed and most cited data processing methods is discussed. In addn., commonly used chemometric and machine learning anal. methods as well as validation approaches are described. [on SciFinder(R)]},
   keywords = {review metabolomics data processing multivariate validation},
   year = {2011}
}

@article{
   author = {Ellis, D. I. and Goodacre, R.},
   title = {Metabolic fingerprinting in disease diagnosis: biomedical applications of infrared and Raman spectroscopy},
   journal = {Analyst},
   volume = {131},
   number = {8},
   pages = {875-885},
   note = {066ED
Times Cited:139
Cited References Count:180},
   abstract = {The ability to diagnose the early onset of disease, rapidly, non-invasively and unequivocally has multiple benefits. These include the early intervention of therapeutic strategies leading to a reduction in morbidity and mortality, and the releasing of economic resources within overburdened health care systems. Some of the routine clinical tests currently in use are known to be unsuitable or unreliable. In addition, these often rely on single disease markers which are inappropriate when multiple factors are involved. Many diseases are a result of metabolic disorders, therefore it is logical to measure metabolism directly. One of the strategies employed by the emergent science of metabolomics is metabolic fingerprinting; which involves rapid, high-throughput global analysis to discriminate between samples of different biological status or origin. This review focuses on a selective number of recent studies where metabolic fingerprinting has been forwarded as a potential tool for disease diagnosis using infrared and Raman spectroscopies.},
   keywords = {uv resonance raman
prostate-specific antigen
ft-ir microspectroscopy
bovine spongiform encephalopathy
principal component analysis
chronic lymphocytic-leukemia
creutzfeldt-jakob-disease
breast-cancer detection
cervical-cancer
human tissue},
   year = {2006}
}

@article{
   author = {Ellis, David I. and Goodacre, Royston},
   title = {Metabolic fingerprinting in disease diagnosis: biomedical applications of infrared and Raman spectroscopy},
   journal = {Analyst (Cambridge, U. K.)},
   volume = {131},
   number = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.},
   pages = {875-885},
   note = {CAPLUS AN 2006:722316(Journal; General Review)},
   abstract = {A review. The ability to diagnose the early onset of disease, rapidly, noninvasively and unequivocally has multiple benefits. These include the early intervention of therapeutic strategies leading to a redn. in morbidity and mortality, and the releasing of economic resources within overburdened health care systems. Some of the routine clin. tests currently in use are known to be unsuitable or unreliable. In addn., these often rely on single disease markers which are inappropriate when multiple factors are involved. Many diseases are a result of metabolic disorders, therefore it is logical to measure metab. directly. One of the strategies employed by the emergent science of metabolomics is metabolic fingerprinting; which involves rapid, high-throughput global anal. to discriminate between samples of different biol. status or origin. This review focuses on a selective no. of recent studies where metabolic fingerprinting has been forwarded as a potential tool for disease diagnosis using IR and Raman spectroscopies. [on SciFinder(R)]},
   keywords = {review metabolic fingerprinting disease diagnosis IR Raman spectroscopy},
   year = {2006}
}

@article{
   author = {Eriksson, Lennart and Johansson, Erik and Muller, Martin and Wold, Svante},
   title = {On the selection of the training set in environmental QSAR analysis when compounds are clustered},
   journal = {J. Chemom.},
   volume = {14},
   number = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.},
   pages = {599-616},
   note = {CAPLUS AN 2000:775976(Journal)},
   abstract = {In QSAR anal. in environmental sciences, adverse effects of chems. released to the environment are modeled and predicted as a function of the chem. properties of the pollutants. Usually the set of compds. under study contains several classes of substances, i.e., a more or less strongly clustered set. It is then needed to ensure that the selected training set comprises compds. representing all those chem. classes. Multivariate design in the principal properties of the compd. classes is usually appropriate for selecting a meaningful training set. However, with clustered data, often seen in environmental chem. and toxicol., a single multivariate design may be suboptimal because of the risk of ignoring small classes with few members and only selecting training set compds. from the largest classes. Recently a procedure for training set selection recognizing clustering was proposed by the authors. In this approach, when non-selective biol. or environmental responses are modeled, local multivariate designs are constructed within each cluster (class). The chosen compds. arising from the local designs are finally united in the overall training set, which thus will contain members from all clusters. The proposed strategy is here further tested and elaborated by applying it to a series of 351 chem. substances for which the soil sorption coeff. is available. These compds. are divided into 14 classes contg. between 10 and 52 members. The training set selection is discussed, followed by multivariate QSAR modeling, model interpretation and predictions for the test set. Various types of statistical exptl. are tested during the training set selection phase. [on SciFinder(R)]},
   keywords = {QSAR modeling soil sorption},
   year = {2000}
}

@article{
   author = {Eriksson, L. and Trygg, J. and Wold, S.},
   title = {CV-ANOVA for significance testing of PLS and OPLS (R) models},
   journal = {Journal of Chemometrics},
   volume = {22},
   number = {11-12},
   pages = {594-600},
   note = {388KA
Times Cited:24
Cited References Count:21},
   abstract = {This report describes significance testing for PLS and OPLS(R) (orthogonal PLS) models. The testing is applicable to single-Y cases and is based on ANOVA of the cross-validated residuals (CV-ANOVA). Two variants of the CV-ANOVA are introduced. The first is based on the cross-validated predictive residuals of the PLS or OPLS model while the second works with the cross-validated predictive score values of the OPLS model. The two CV-ANOVA diagnostics are shown to work well in those cases where PLS and OPLS work well, that is, for data with many and correlated variables, missing data, etc. The utility of the CV-ANOVA diagnostic is demonstrated using three datasets related to (i) the monitoring of an industrial de-inking process; (ii) a pharmaceutical QSAR problem and (iii) a multivariate calibration application from a sugar refinery. Copyright (C) 2008 John Wiley & Sons, Ltd.},
   keywords = {significance testing
opls
cross-validation
anova
predictive score
multivariate
regression},
   year = {2008}
}

@article{
   author = {Forshed, J. and Idborg, H. and Jacobsson, S. P.},
   title = {Evaluation of different techniques for data fusion of LC/MS and H-1-NMR},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {85},
   number = {1},
   pages = {102-109},
   note = {128AU
Times Cited:16
Cited References Count:34},
   abstract = {In the analyses of highly complex samples (for example, metabolic fingerprinting), the data might not suffice for classification when using only a single analytical technique. Hence, the use of two complementary techniques, e.g., LUMS and H-1-NMR, might be advantageous. Another possible advantage from using two different techniques is the ability to verify the results (for instance, by verifying a time trend of a metabolic pattern). In this work, both LC/MS and H-1-NMR data from analysis of rat urine have been used to obtain metabolic fingerprints. A comparison of three different methods for data fusion of the two data sets was performed and the possibilities and difficulties associated with data fusion were discussed. When comparing concatenated data, full hierarchical modeling, and batch modeling, the first two approaches were found to be the most successful. Different types of block scaling and variable scaling were evaluated and the optimal scaling for each case was found by cross validation. Validations of the final models were performed by means of an external test set.(2) (c) 2006 Elsevier B.V. All rights reserved.},
   keywords = {h-1-nmr
lc/ms
data fusion
data concatenation
hierarchical modeling
batch modeling
partial least-squares
hierarchical pca
2-way data
rat urine
metabonomics
multiblock
pls
discrimination
chromatography
metabolites},
   year = {2007}
}

@article{
   author = {Forshed, Jenny and Schuppe-Koistinen, Ina and Jacobsson, Sven P.},
   title = {Peak alignment of NMR signals by means of a genetic algorithm},
   journal = {Anal. Chim. Acta},
   volume = {487},
   number = {2},
   pages = {189-199},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2003:495853(Journal)
10.1016/S0003-2670(03)00570-1},
   abstract = {NMR anal. of complex samples, such as biofluid samples is accompanied by variations in peak position and peak shape not directly related to the sample. This is due to variations in the background matrix of the sample and to instrumental instabilities. These variations complicate and limit the interpretation and anal. of NMR data by multivariate methods. Alignment of the NMR signals may circumvent these limitations and is an important preprocessing step prior to multivariate anal. Previous aligning methods reduce the spectral resoln., are very computer-intensive for this kind of data (65k data points in one spectrum), or rely on peak detection. The method presented in this work requires neither data redn. nor preprocessing, e.g. peak detection. The alignment is achieved by taking each segment of the spectrum individually, shifting it sidewise, and linearly interpolating it to stretch or shrink until the best correlation with a corresponding ref. spectrum segment is obtained. The segments are automatically picked out with a routine, which avoids cutting in a peak, and the optimization process is accomplished by means of a genetic algorithm (GA). The peak alignment routine is applied to NMR metabonomic data. [on SciFinder(R)]},
   keywords = {peak alignment NMR spectrometry signal genetic algorithm},
   year = {2003}
}

@article{
   author = {Garcia-Perez, I. and Vallejo, M. and Garcia, A. and Legido-Quigley, C. and Barbas, C.},
   title = {Metabolic fingerprinting with capillary electrophoresis},
   journal = {Journal of Chromatography A},
   volume = {1204},
   number = {2},
   pages = {130-139},
   note = {353TK
Times Cited:30
Cited References Count:98},
   abstract = {Increasingly biomedical studies require a top-down approach that can be achieved by comparing patterns, signatures or "fingerprints" of metabolites that change in response to disease, toxin exposure, environmental or genetic alterations. Capillary electrophoresis is a technique well suited for the analysis of biofluids and extracted tissue. The experimental design requires a multidisciplinary team comprising chemists, informaticians, medics, etc. Here we have reviewed the field of CE fingerprinting and organised the manuscript in four main blocks, Sample treatment is a discussion of the latest methods for extraction of compounds, Analytical methods, deals with the different versions of electrophoretic methods and detection instrumentation, Chemometrics and CE fingerprinting, explains algorithms that have been presented for peak alignment, normalization, data analysis and metabolite identification, and the Applications heading focuses in urine, plasma, organic matter and plant extract studies. (c) 2008 Elsevier B.V. All rights reserved.},
   keywords = {metabolomic
metabonomic
chemometrics
multivariate data analysis
bioanalysis
profiling
ionization-mass-spectrometry
artificial neural-networks
multivariate data-analysis
base-line correction
zone-electrophoresis
chromatographic data
pattern-recognition
gas-chromatography
sample preparation
organic acidurias},
   year = {2008}
}

@article{
   author = {Gebregiworgis, T. and Powers, R.},
   title = {Application of NMR Metabolomics to Search for Human Disease Biomarkers.},
   journal = {Comb. Chem. High Throughput Screening},
   volume = {15},
   number = {8},
   pages = {595-610},
   year = {2012}
}

@article{
   author = {Geladi, P. and Kowalski, B. R.},
   title = {Partial Least-Squares Regression - a Tutorial},
   journal = {Analytica Chimica Acta},
   volume = {185},
   pages = {1-17},
   note = {E4775
Times Cited:2154
Cited References Count:11},
   year = {1986}
}

@article{
   author = {Geladi, P. and Manley, M. and Lestander, T.},
   title = {Scatter plotting in multivariate data analysis},
   journal = {Journal of Chemometrics},
   volume = {17},
   number = {8-9},
   pages = {503-511},
   note = {736GL
Times Cited:17
Cited References Count:32},
   abstract = {In data analysis, many situations arise where plotting and visualization are helpful or an absolute requirement for understanding. There are many techniques of plotting data/parameters/residuals. These have to be understood and visualization has to be made clearly and interpreted correctly. In this paper the classical favourites in chemometrics, scatter plots, are looked into more deeply and some criticism based on recent literature references is formulated for situations of principal component analysis, PARAFAC three-way analysis and regression by partial least squares. Biplots are also afforded some attention. Examples from near-infrared spectroscopy are given as illustrations. Copyright (C) 2003 John Wiley Sons, Ltd.},
   keywords = {plotting
visualization
multivariate data analysis
line plots
interpretation of scatter plots
biplots
near-infrared spectroscopy
principal component analysis
parafac
partial least squares regression
near-infrared spectroscopy
batch organic-synthesis
multiway analysis},
   year = {2003}
}

@article{
   author = {Golbraikh, A. and Tropsha, A.},
   title = {Beware of q(2)!},
   journal = {Journal of Molecular Graphics & Modelling},
   volume = {20},
   number = {4},
   pages = {269-276},
   note = {518HP
Times Cited:1004
Cited References Count:44},
   abstract = {Validation is a crucial aspect of any quantitative structure-activity relationship (QSAR) modeling. This paper examines one of the most popular validation criteria, leave-one-out cross-validated R-2 (LOO q(2)). Often, a high value of this statistical characteristic (q(2) > 0.5) is considered as a proof of the high predictive ability of the model. In this paper, we show that this assumption is generally incorrect. In the case of 3D QSAR, the lack of the correlation between the high LOO q(2) and the high predictive ability of a QSAR model has been established earlier [Pharm. Acta Heiv. 70 (1995) 149; J. Chemomet. 10 (1996) 95; J. Med. Chem. 41 (1998) 2553]. In this paper, we use two-dimensional (2D) molecular descriptors and k nearest neighbors (kNN) QSAR method for the analysis of several datasets. No correlation between the values of q(2) for the training set and predictive ability for the test set was found for any of the datasets. Thus, the high value of LOO q(2) appears to be the necessary but not the sufficient condition for the model to have a high predictive power. We argue that this is the general property of QSAR models developed using LOO cross-validation. We emphasize that the external validation is the only way to establish a reliable QSAR model. We formulate a set of criteria for evaluation of predictive ability of QSAR models. (C) 2002 Elsevier Science Inc. All rights reserved.},
   keywords = {qsar modeling
loo cross-validation
training and test sets
knn qsar
molecular-field analysis
combinatorial library design
electrotopological state
variable selection
3d qsar
index
graphs
comfa
shape
information},
   year = {2002}
}

@article{
   author = {Goodacre, R. and Broadhurst, D. and Smilde, A. K. and Kristal, B. S. and Baker, J. D. and Beger, R. and Bessant, C. and Connor, S. and Calmani, G. and Craig, A. and Ebbels, T. and Kell, D. B. and Manetti, C. and Newton, J. and Paternostro, G. and Somorjai, R. and Sjostrom, M. and Trygg, J. and Wulfert, F.},
   title = {Proposed minimum reporting standards for data analysis in metabolomics},
   journal = {Metabolomics},
   volume = {3},
   number = {3},
   pages = {231-241},
   note = {217JZ
Times Cited:49
Cited References Count:68},
   abstract = {The goal of this group is to define the reporting requirements associated with the statistical analysis (including univariate, multivariate, informatics, machine learning etc.) of metabolite data with respect to other measured/collected experimental data (often called metadata). These definitions will embrace as many aspects of a complete metabolomics study as possible at this time. In chronological order this will include: Experimental Design, both in terms of sample collection/matching, and data acquisition scheduling of samples through whichever spectroscopic technology used; Deconvolution (if required); Pre-processing, for example, data cleaning, outlier detection, row/column scaling, or other transformations; Definition and parameterization of subsequent visualizations and Statistical/Machine learning Methods applied to the dataset; If required, a clear definition of the Model Validation Scheme used (including how data are split into training/validation/test sets); Formal indication on whether the data analysis has been Independently Tested (either by experimental reproduction, or blind hold out test set). Finally, data interpretation and the visual representations and hypotheses obtained from the data analyses.},
   keywords = {chemometrics
multivariate
megavariate
unsupervised learning
supervised learning
informatics
bioinformatics
statistics
biostatistics
machine learning
statistical learning
pattern-recognition
time-domain
data sets
nmr
biomarkers
spectroscopy
validation
reproducibility
identification
deconvolution},
   year = {2007}
}

@article{
   author = {Goodacre, R. and York, E. V. and Heald, J. K. and Scott, I. M.},
   title = {Chemometric discrimination of unfractionated plant extracts analyzed by electrospray mass spectrometry},
   journal = {Phytochemistry},
   volume = {62},
   number = {6},
   pages = {859-863},
   note = {652VD
Times Cited:59
Cited References Count:31},
   abstract = {Metabolic fingerprints were obtained from unfractionated Pharbitis nil leaf sap samples by direct infusion into an electrospray ionization mass spectrometer. Analyses took less than 30 s per sample and yielded complex mass spectra. Various chemometric methods, including discriminant function analysis and the machine-learning methods of artificial neural networks and genetic programming, could discriminate the metabolic fingerprints of plants subjected to different photoperiod treatments. This rapid automated analytical procedure could find use in a variety of phytochemical applications requiring high sample throughput. (C) 2003 Elsevier Science Ltd. All rights reserved.},
   keywords = {pharbitis nil
convolvulaceae
japanese morning glory
electrospray ionization mass spectrometry
neural networks
genetic programming
metabolic fingerprinting
transform infrared-spectroscopy
neural networks
identification
chromatography
metabolites
expression
bacteria},
   year = {2003}
}

@article{
   author = {Goodpaster, A. M. and Kennedy, M. A.},
   title = {Quantification and statistical significance analysis of group separation in NMR-based metabonomics studies},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {109},
   number = {2},
   pages = {162-170},
   note = {852YG
Times Cited:1
Cited References Count:13},
   abstract = {Currently, no standard metrics are used to quantify cluster separation in PCA or PLS-DA scores plots for meta-bonomics studies or to determine if cluster separation is statistically significant. lack of such measures makes it virtually impossible to compare independent or inter-laboratory studies and can lead to confusion in the metabonomics literature when authors putatively identify metabolites distinguishing classes of samples based on visual and qualitative inspection of scores plots that exhibit marginal separation. While previous papers have addressed quantification of cluster separation in PCA scores plots, none have advocated routine use of a quantitative measure of separation that is supported by a standard and rigorous assessment of whether or not the cluster separation is statistically significant. Here quantification and statistical significance of separation of group centroids in PCA and PLS-DA scores plots are considered. The Mahalanobis distance is used to quantify the distance between group centroids, and the two-sample Hotelling's T(2) test is computed for the data, related to an F-statistic, and then an F-test is applied to determine if the cluster separation is statistically significant. We demonstrate the value of this approach using four datasets containing various degrees of separation, ranging from groups that had no apparent visual cluster separation to groups that had no visual cluster overlap. Widespread adoption of such concrete metrics to quantify and evaluate the statistical significance of PCA and PLS-DA cluster separation would help standardize reporting of metabonomics data. (C) 2011 Elsevier B.V. All rights reserved.},
   keywords = {pca
pls-da
scores plot
metabonomics
cluster separation
statistical significance
mouse urine},
   year = {2011}
}

@article{
   author = {Hall, Robert D.},
   title = {Plant metabolomics in a nutshell: potential and future challenges},
   journal = {Annu. Plant Rev.},
   volume = {43},
   number = {Biology of Plant Metabolomics},
   pages = {1-24},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:1001323(Journal; General Review)
10.1002/9781444339956.ch1},
   abstract = {A review. In just 10 years, plant metabolomics has been transformed from a purely theor. concept into a highly valued and widely exploited technol. Moving on from the many and wide-ranging hopes, enthused upon in a multitude of early reviews, metabolomics for plant research has already proved itself despite the technol. still experiencing certain limitations. We have a long road to travel before we reach our desired destination - a very happy place where large-scale, (semi-) automated, unbiased multiplex analyses of plant materials, leading to exhaustive lists of named metabolites become possible. This biochem. Holy Grail will, by definition, never be reached. Nevertheless, continued advances in hardware, software and biostatistics are enabling us to generate ever-advancing, detailed insights into the chem. compn. of plants and how this is influenced by genetical and environmental perturbation. There continues to be a major driving force behind further developments, spurred on by myriad existing and potentially new applications in both applied and fundamental plant science. It is no longer so much a case of hope springs eternal but rather, who dares wins! [on SciFinder(R)]},
   keywords = {review plant metabolomics},
   year = {2011}
}

@article{
   author = {Halouska, S. and Powers, R.},
   title = {Negative impact of noise on the principal component analysis of NMR data},
   journal = {Journal of Magnetic Resonance},
   volume = {178},
   number = {1},
   pages = {88-95},
   note = {003ZV
Times Cited:30
Cited References Count:21},
   abstract = {Principal component analysis (PCA) is routinely applied to the study of NMR based metabolomic data. PCA is used to simplify the examination of complex metabolite mixtures obtained from biological samples that may be composed of hundreds or thousands of chemical components. PCA is primarily used to identify relative changes in the concentration of metabolites to identify trends or characteristics within the NMR data that permits discrimination between various samples that differ in their source or treatment. A common concern with PCA of NMR data is the potential over emphasis of small changes in high concentration metabolites that would over-shadow significant and large changes in low-concentration components that may lead to a skewed or irrelevant clustering of the NMR data. We have identified an additional concern, very small and random fluctuations within the noise of the NMR spectrum can also result in large and irrelevant variations in the PCA clustering. Alleviation of this problem is obtained by simply excluding the noise region from the PCA by a judicious choice of a threshold above the spectral noise. (c) 2005 Elsevier Inc. All rights reserved.},
   keywords = {principal component analysis
metabolomics
impact of noise
nmr
pattern-recognition methods
magnetic-resonance
functional genomics
metabonomics
spectroscopy
metabolomics
spectra
urine
rat},
   year = {2006}
}

@article{
   author = {Han, Jun and Datla, Raju and Chan, Sammy and Borchers, Christoph H.},
   title = {Mass spectrometry-based technologies for high-throughput metabolomics},
   journal = {Bioanalysis},
   volume = {1},
   number = {9},
   pages = {1665-1684},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2010:60492(Journal; General Review)
10.4155/bio.09.158},
   abstract = {A review. The metabolome is composed of a vast no. of small-mol. metabolites that exhibit a diversity of phys. and chem. properties and exist over a wide dynamic range in biol. samples. Multiple anal. techniques, used in a complementary manner, are required to achieve high coverage of the metabolome. MS is playing a central role in metabolomics research. Herein, we present a brief overview of the MS-based technologies employed for high-throughput metabolomics. These technologies range from chromatog.-MS techniques, such as GC-MS and LC-MS, to chromatog.-free techniques, such as direct infusion, matrix-assisted and matrix-free laser desorption/ionization, imaging and some new ambient ionization approaches. Chemoinformatics and bioinformatics tools are widely available to facilitate successful metabolomics studies by turning the complex metabolomics data into biol. information through streamlined data processing, anal. and interpretation. [on SciFinder(R)]},
   keywords = {review mass spectrometry high throughput screening metabolomic},
   year = {2009}
}

@article{
   author = {Hoefsloot, H. C. J. and Verouden, M. P. H. and Westerhuis, J. A. and Smilde, A. K.},
   title = {Maximum likelihood scaling (MALS)},
   journal = {Journal of Chemometrics},
   volume = {20},
   number = {3-4},
   pages = {120-127},
   note = {157ZS
Times Cited:1
Cited References Count:14},
   abstract = {A filtering procedure is introduced for multivariate data that does not suffer from noise amplification by scaling. A maximum likelihood principal component analysis (MLPCA) step is used as a filter that partly removes noise. This filtering can be used prior to any subsequent scaling and multivariate analysis of the data and is especially useful for data with moderate and low signal-to-noise ratio's, such as metabolomics, proteomics and transcriptomics data. Copyright (c) 2007 John Wiley & Sons, Ltd.},
   keywords = {scaling
preprocessing
omics-data
noise
filtering
principal component analysis
least-squares algorithms
heteroscedastic noise
profiles},
   year = {2006}
}

@article{
   author = {Hoskuldsson, A.},
   title = {Variable and subset selection in PLS regression},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {55},
   number = {1-2},
   pages = {23-38},
   note = {408VA
Times Cited:111
Cited References Count:8},
   abstract = {The purpose of this paper is to present some useful methods for introductory analysis of variables and subsets in relation to PLS regression. We present here methods that are efficient in finding the appropriate variables or subset to use in the PLS regression. The general conclusion is that variable selection is important for successful analysis of chemometric data. An important aspect of the results presented is that lack of variable selection can spoil the PLS regression, and that cross-validation measures using a test set can show larger variation, when we use different subsets of X, than obtained by different methods. We also present an approach to orthogonal scatter correction. The procedures and comparisons are applied to industrial data. (C) 2001 Elsevier Science B.V. All rights reserved.},
   keywords = {variable selection
partial least squares (pls)
principal component analysis (pca)
h-principle
stepwise regression
orthogonal scatter correction (osc)
orthogonal signal correction
near-infrared spectra},
   year = {2001}
}

@article{
   author = {Hotelling, Harold},
   title = {Analysis of a complex of statistical variables into principal components},
   journal = {Journal of Educational Psychology},
   volume = {24},
   number = {7},
   pages = {22},
   year = {1933}
}

@article{
   author = {Johnstone, I. M. and Titterington, D. M.},
   title = {Statistical challenges of high-dimensional data INTRODUCTION},
   journal = {Philosophical Transactions of the Royal Society a-Mathematical Physical and Engineering Sciences},
   volume = {367},
   number = {1906},
   pages = {4237-4253},
   note = {507OP
Times Cited:5
Cited References Count:52},
   abstract = {Modern applications of statistical theory and methods can involve extremely large datasets, often with huge numbers of measurements on each of a comparatively small number of experimental units. New methodology and accompanying theory have emerged in response: the goal of this Theme Issue is to illustrate a number of these recent developments. This overview article introduces the difficulties that arise with high-dimensional data in the context of the very familiar linear statistical model: we give a taste of what can nevertheless be achieved when the parameter vector of interest is sparse, that is, contains many zero elements. We describe other ways of identifying low-dimensional subspaces of the data space that contain all useful information. The topic of classification is then reviewed along with the problem of identifying, from within a very large set, the variables that help to classify observations. Brief mention is made of the visualization of high-dimensional data and ways to handle computational problems in Bayesian analysis are described. At appropriate points, reference is made to the other papers in the issue.},
   keywords = {bayesian analysis
classification
cluster analysis
high-dimensional data
regression
sparsity
dantzig selector
useful features
reduction
regression
classification
eigenmaps
models
lasso
rare
weak},
   year = {2009}
}

@book{
   author = {Jolliffe, I. T.},
   title = {Principal Component Analysis},
   publisher = {Springer},
   edition = {2},
   series = {Springer Series in Statistics},
   year = {2002}
}

@article{
   author = {Kell, D. B.},
   title = {Metabolomics and systems biology: making sense of the soup},
   journal = {Current Opinion in Microbiology},
   volume = {7},
   number = {3},
   pages = {296-307},
   note = {836CY
Times Cited:225
Cited References Count:157},
   abstract = {Novel techniques for acquiring metabolomics data continue to emerge. Such data require proper storage in suitably configured databases, which then permit one to establish the size of microbial metabolomes (hundreds of major metabolites) and allow the nature, organisation and control of metabolic networks to be investigated. A variety of algorithms for metabolic network reconstruction coupled to suitable modelling algorithms are the ground substances for the development of metabolic network and systems biology. Even qualitative models of metabolic networks, when subject to stoichiometric constraints, can prove highly informative, and are the first step to the quantitative models, which alone can allow the true representation of complex biochemical systems.},
   keywords = {magnetic-resonance-spectroscopy
2-dimensional gas-chromatography
electrospray mass-spectrometry
hplc-nmr-ms
escherichia-coli
functional genomics
structure elucidation
explanatory analysis
microarray data
drug discovery},
   year = {2004}
}

@article{
   author = {Keun, H. C. and Ebbels, T. M. D. and Antti, H. and Bollard, M. E. and Beckonert, O. and Holmes, E. and Lindon, J. C. and Nicholson, J. K.},
   title = {Improved analysis of multivariate data by variable stability scaling: application to NMR-based metabolic profiling},
   journal = {Analytica Chimica Acta},
   volume = {490},
   number = {1-2},
   pages = {265-276},
   note = {716UP
Times Cited:86
Cited References Count:15},
   abstract = {Variable scaling alters the covariance structure of data, affecting the outcome of multivariate analysis and calibration. Here we present a new method, variable stability (VAST) scaling, which weights each variable according to a metric of its stability. The beneficial effect of VAST scaling is demonstrated for a data set of H-1 NMR spectra of urine acquired as part of a metabonomic study into the effects of unilateral nephrectomy in an animal model. The application of VAST scaling improved the class distinction and predictive power of partial least squares discriminant analysis (PLS-DA) models. The effects of other data scaling and pre-processing methods, such as orthogonal signal correction (OSC), were also tested. VAST scaling produced the most robust models in terms of class prediction, outperforming OSC in this aspect. As a result the subtle, but consistent, metabolic perturbation caused by unilateral nephrectomy could be accurately characterised despite the presence of much greater biological differences caused by normal physiological variation. VAST scaling presents itself as an interpretable, robust and easily implemented data treatment for the enhancement of multivariate data analysis. (C) 2003 Elsevier Science B.V. All rights reserved.},
   keywords = {orthogonal signal correction
variable scaling
coefficient of variations
metabonomics
metabolomics
partial least squares discriminant analysis
variable stability
data pre-processing
biofluid nmr
orthogonal signal correction
spectra
toxicity
biofluids},
   year = {2003}
}

@article{
   author = {Kind, Tobias and Wohlgemuth, Gert and Lee, Do Yup and Lu, Yun and Palazoglu, Mine and Shahbaz, Sevini and Fiehn, Oliver},
   title = {FiehnLib: Mass Spectral and Retention Index Libraries for Metabolomics Based on Quadrupole and Time-of-Flight Gas Chromatography/Mass Spectrometry},
   journal = {Anal. Chem. (Washington, DC, U. S.)},
   volume = {81},
   number = {24},
   pages = {10038-10048},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2009:1454463(Journal)
10.1021/ac9019522},
   abstract = {At least two independent parameters are necessary for compd. identification in metabolomics. We have compiled 2212 electron impact mass spectra and retention indexes for quadrupole and time-of-flight gas chromatog./mass spectrometry (GC/MS) for over 1000 primary metabolites below 550 Da, covering lipids, amino acids, fatty acids, amines, alcs., sugars, amino-sugars, sugar alcs., sugar acids, org. phosphates, hydroxyl acids, aroms., purines, and sterols as methoximated and trimethylsilylated mass spectra under electron impact ionization. Compds. were selected from different metabolic pathway databases. The structural diversity of the libraries was found to be highly overlapping with metabolites represented in the BioMeta/KEGG pathway database using chem. fingerprints and calcns. using Instant-JChem. In total, the FiehnLib libraries comprised 68% more compds. and twice as many spectra with higher spectral diversity than the public Golm Metabolite Database. A range of unique compds. are present in the FiehnLib libraries that are not comprised in the 4345 trimethylsilylated spectra of the com. NIST05 mass spectral database. The libraries can be used in conjunction with GC/MS software but also support compd. identification in the public BinBase metabolomic database that currently comprises 5598 unique mass spectra generated from 19032 samples covering 279 studies of 47 species (plants, animals, and microorganisms). [on SciFinder(R)]},
   keywords = {FiehnLib library database mass spectrometry gas chromatog carbohydrate lipid},
   year = {2009}
}

@article{
   author = {Kjeldahl, K. and Bro, R.},
   title = {Some common misunderstandings in chemometrics},
   journal = {Journal of Chemometrics},
   volume = {24},
   number = {7-8},
   pages = {558-564},
   note = {657JA
Times Cited:12
Cited References Count:17},
   abstract = {This paper describes a number of issues and tools in practical chemometric data analysis that are often either misunderstood or misused. Deciding what are relevant samples and variables, (mis-)use of common model diagnostics, and interpretational issues are addressed in relation to component models such as PCA and PLS models. Along with simple misunderstandings, the use of chemometric software packages may contribute to the mistakes if not used critically, and it is thus a main conclusion that good data analysis practice requires the analyst to take responsibility and do what is relevant for the given purpose. Copyright (C) 2010 John Wiley & Sons, Ltd.},
   keywords = {pca
pls
misunderstandings
model interpretation
data analysis
variable selection
model validation},
   year = {2010}
}

@article{
   author = {Koh, P. and Chan, E. and Mal, M. and Eu, K. and Blackshall, A. and Keun, H.},
   title = {Metabolic Profiling of Human Colorectal Cancer Using High-Resolution Magic Angle Spinning Nuclear Magnetic Resonance (Hr-Mas Nmr) Spectroscopy and Gas Chromatography Mass Spectrometry (Gc/Ms).},
   journal = {Diseases of the Colon & Rectum},
   volume = {52},
   number = {4},
   pages = {769-769},
   note = {544GZ
Times Cited:0
Cited References Count:0},
   year = {2009}
}

@article{
   author = {Ledauphin, J. and Le Milbeau, C. and Barillier, D. and Hennequin, D.},
   title = {Differences in the Volatile Compositions of French Labeled Brandies (Armagnac, Calvados, Cognac, and Mirabelle) Using GC-MS and PLS-DA},
   journal = {Journal of Agricultural and Food Chemistry},
   volume = {58},
   number = {13},
   pages = {7782-7793},
   note = {621JX
Times Cited:3
Cited References Count:56},
   abstract = {A total of 207 volatile compounds were identified in extracts of four French labeled brandies: Armagnac, Cognac, Calvados, and Mirabelle. Relative levels of all components were determined using GC-MS after integration of a selected peak of the mass spectrum of each. Each type of brandy could be clearly discriminated using PLS-DA statistical analyses based on these levels. French Mirabelle spirit, which was studied for the first time, was characterized by higher levels of many aldehydes and acetals and by the presence of compounds having an odd number of carbons together with benzaldehyde and some of its derivatives. Many possible derivatives of acrolein and high amounts of butan-2-ol were rather specific for the volatile composition of Calvados. The most important difference between the two wine-based samples seemed to be directly linked to the distillation system used. Many furanic compounds are specific to Cognac, whereas two or three compounds such as 1-(ethoxyethoxy)-2-methylbutane and gamma-eudesmol were specific to Armagnac. These two brandies presented rather high distributions of isobutanol and isopentanols, whereas Mirabelle and Calvados compositions offer more concentrated aliphatic linear alcohols.},
   keywords = {volatile composition
gc-ms
brandies
discrimination
pls-da analysis
solid-phase microextraction
chromatography-mass spectrometry
freshly distilled calvados
sensory aroma characterization
extract dilution analysis
aged red wines
gas-chromatography
oak wood
glycerol metabolism
orujo spirits},
   year = {2010}
}

@article{
   author = {Li, H. D. and Liang, Y. Z. and Xu, Q. S.},
   title = {Support vector machines and its applications in chemistry},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {95},
   number = {2},
   pages = {188-198},
   note = {407YP
Times Cited:52
Cited References Count:84},
   abstract = {Support vector machines (SVMs) are a promising machine learning method originally developed for pattern recognition problem based on structural risk minimization. Functionally, SVMs can be divided into two categories: support vector classification (SVC) machines and support vector regression (SVR) machines. According to this classification, their basic elements and algorithms are discussed in some detail and selected applications on two real world datasets and two simulated datasets are conducted to elucidate the good generalization performance of SVMs, specially good for treating the data of some nonlineartiy. (C) 2008 Elsevier B.V. All rights reserved.},
   keywords = {support vector machines
pattern recognition
regression
nonlinearity
partial least-squares
near-infrared spectroscopy
quadratic discriminant-analysis
radial basis functions
pattern-recognition
projection pursuit
variable-selection
cross-validation
heuristic method
neural-networks},
   year = {2009}
}

@article{
   author = {Li, M. and Wang, B. H. and Zhang, M. H. and Rantalainen, M. and Wang, S. Y. and Zhou, H. K. and Zhang, Y. and Shen, J. and Pang, X. Y. and Zhang, M. L. and Wei, H. and Chen, Y. and Lu, H. F. and Zuo, J. and Su, M. M. and Qiu, Y. P. and Jia, W. and Xiao, C. N. and Smith, L. M. and Yang, S. L. and Holmes, E. and Tang, H. R. and Zhao, G. P. and Nicholson, J. K. and Li, L. J. and Zhao, L. P.},
   title = {Symbiotic gut microbes modulate human metabolic phenotypes},
   journal = {Proceedings of the National Academy of Sciences of the United States of America},
   volume = {105},
   number = {6},
   pages = {2117-2122},
   note = {264CC
Times Cited:224
Cited References Count:38},
   abstract = {Humans have evolved intimate symbiotic relationships with a consortium of gut microbes (microbiome) and individual variations in the microbiome influence host health, may be implicated in disease etiology, and affect drug metabolism, toxicity, and efficacy. However, the molecular basis of these microbe-host interactions and the roles of individual bacterial species are obscure. We now demonstrate a "transgenomic" approach to link gut microbiome and metabolic phenotype (metabotype) variation. We have used a combination of spectroscopic, microbiomic, and multivariate statistical tools to analyze fecal and urinary samples from seven Chinese individuals (sampled twice) and to model the microbial-host metabolic connectivities. At the species level, we found structural differences in the Chinese family gut microbiomes and those reported for American volunteers, which is consistent with population microbial cometabolic differences reported in epidemiological studies. We also introduce the concept of functional metagenomics, defined as "the characterization of key functional members of the microbiome that most influence host metabolism and hence health." For example, Faecalibacterium prausnitzii population variation is associated with modulation of eight urinary metabolites of diverse structure, indicating that this species is a highly functionally active member of the microbiome, influencing numerous host pathways. Other species were identified showing different and varied metabolic interactions. Our approach for understanding the dynamic basis of host-microbiome symbiosis provides a foundation for the development of functional metagenomics as a probe of systemic effects of drugs and diet that are of relevance to personal and public health care solutions.},
   keywords = {covariation analysis
gut microbiota
metabonomics
metabotype
metagenomics
gradient gel-electrophoresis
16s ribosomal-rna
systems biology
clone libraries
reveals
spectroscopy
populations
ecology
obesity
genes},
   year = {2008}
}

@article{
   author = {Lindon, J. C. and Nicholson, J. K. and Holmes, E. and Everett, J. R.},
   title = {Metabonomics: Metabolic processes studied by NMR spectroscopy of biofluids},
   journal = {Concepts in Magnetic Resonance},
   volume = {12},
   number = {5},
   pages = {289-320},
   note = {346HG
Times Cited:206
Cited References Count:93},
   abstract = {NMR spectroscopy of biofluids provides a wealth of information on the endogenous metabolic processes in an organism Details of the various types of biofluid and the types of NMR experiment which are useful are given. The features of biofluid NMR spectra are described and practical details of spectral acquisition are also presented. However, the spectra are very complex and many resonances have not been assigned. Therefore, in order to focus on significant differences between a set of spectra from control organisms and from abnormals (e.g.. humans with diseases or animals in toxic situations), recourse is made to pattern recognition or chemometric methods. This is exemplifed using NMR spectra of a number of different biofluids such as urine, blood plasma, and cerebrospinal fluid. This approach is encapsulated in the concept of metabonomics, a subject which can be regarded as complementary to studies of the genome (genomics) and the proteins in an organism (proteomics). Metabonomics is defined as "the quantitative measurement of the multiparametric metabolic response of living systems to pathophysiological stimuli or genetic modification." (C) 2000 John Wiley & Sons, Inc.},
   keywords = {nmr spectroscopy
biofluids
metabolites
pattern recognition
chemometrics
classification
toxicity
metabonomics
disease
nuclear-magnetic-resonance
human-blood-plasma
high-resolution h-1-nmr
pattern-recognition classification
automatic data reduction
spin-echo
biological-fluids
malignant-tumors
synovial-fluid
diffusion-diffraction},
   year = {2000}
}

@article{
   author = {Lindon, J. C. and Nicholson, J. K. and Holmes, E. and Keun, H. C. and Craig, A. and Pearce, J. T. M. and Bruce, S. J. and Hardy, N. and Sansone, S. A. and Antti, H. and Jonsson, P. and Daykin, C. and Navarange, M. and Beger, R. D. and Verheij, E. R. and Amberg, A. and Baunsgaard, D. and Cantor, G. H. and Lehman-McKeeman, L. and Earll, M. and Wold, S. and Johansson, E. and Haselden, J. N. and Kramer, K. and Thomas, C. and Lindberg, J. and Schuppe-Koistinen, I. and Wilson, I. D. and Reily, M. D. and Robertson, D. G. and Senn, H. and Krotzky, A. and Kochhar, S. and Powell, J. and van der Ouderaa, F. and Plumb, R. and Schaefer, H. and Spraul, M. and worki, Stand Metab Reporting Struct},
   title = {Summary recommendations for standardization and reporting of metabolic analyses},
   journal = {Nature Biotechnology},
   volume = {23},
   number = {7},
   pages = {833-838},
   note = {944KT
Times Cited:116
Cited References Count:15},
   keywords = {spectrometry
guidelines
strategy
samples},
   year = {2005}
}

@article{
   author = {Mahadevan, S. and Shah, S. L. and Marrie, T. J. and Slupsky, C. M.},
   title = {Analysis of metabolomic data using support vector machines},
   journal = {Analytical Chemistry},
   volume = {80},
   number = {19},
   pages = {7562-7570},
   note = {353XS
Times Cited:47
Cited References Count:27},
   abstract = {Metabolomics is an emerging field providing insight into physiological processes. It is an effective tool to investigate disease diagnosis or conduct toxicological studies by observing changes in metabolite concentrations in various biofluids. Multivariate statistical analysis is generally employed with nuclear magnetic resonance (NMR) or mass spectrometry (MS) data to determine differences between groups (for instance diseased vs healthy). Characteristic predictive models may be built based on a set of training data, and these models are subsequently used to predict whether new test data falls under a specific class. In this study, metabolomic data is obtained by doing a H-1 NMR spectroscopy on urine samples obtained from healthy subjects (male and female) and patients suffering from Streptococcus pneumoniae. We compare the performance of traditional PLS-DA multivariate analysis to support vector machines (SVMs), a technique widely used in genome studies on two case studies: (1) a case where nearly complete distinction may be seen (healthy versus pneumonia) and (2) a case where distinction is more ambiguous (male versus female). We show that SVMs are superior to PLS-DA in both cases in terms of predictive accuracy with the least number of features. With fewer number of features, SVMs are able to give better predictive model when compared to that of PLS-DA.},
   keywords = {gene-expression data
classification
selection
metabonomics
pls},
   year = {2008}
}

@article{
   author = {Martens, Harald A. and Dardenne, Pierre},
   title = {Validation and verification of regression in small data sets},
   journal = {Chemom. Intell. Lab. Syst.},
   volume = {44},
   number = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.},
   pages = {99-121},
   note = {CAPLUS AN 1998:720932(Journal)},
   abstract = {Four different methods of using small data sets in multivariate modeling are compared w.r.t. predictive precision in the long-run. The modeling in this case concerns multivariate calibration: ŷ = f(X). The study consists of a Monte Carlo simulation within a large data base of real data; X = NIR reflectance spectra and y = protein percentage, measured in 922 whole maize plant samples. Small data sets (40-120 objects) were repeatedly selected at random from the data base, each time simulating the situation of having only a small set of samples available for estg., optimizing and assessing calibration the model. The true apparent prediction error was each time controlled in the remaining data base. This was replicated 100 times to study the statistical performance of the four different validation methods. In each Monte Carlo replicate, the splitting of the available data set into calibration set and test set was compared to full cross validation. Removing samples from an already limited set of available samples to an independent VALIDATION TEST SET seriously reduced the predictive performance of the calibrated models, and at the same time gave uncertain, systematically over-optimistic assessment of the models' predictive performance. Full CROSS VALIDATION gave improved predictive performance, and gave only slightly over-optimistic assessment of this predictive performance. Further removal of even more of the available samples for use in an independent VERIFICATION TEST SET gave in-the-long-run correct, although uncertain ests. of the predictive performance of the calibrated models, but this performance level had seriously deteriorated. Alternative verification of the model's predictive performance by the method of CROSS VERIFICATION gave results very similar to those of the cross validation. These results from real data correspond closely to previous findings for artificially simulated data. It appears that full cross validation is superior to both the use of independent validation test set and independent verification test set. [on SciFinder(R)]},
   keywords = {validation verification regression},
   year = {1998}
}

@article{
   author = {McNiven, Elizabeth M. S. and German, J. Bruce and Slupsky, Carolyn M.},
   title = {Analytical metabolomics: nutritional opportunities for personalized health},
   journal = {J. Nutr. Biochem.},
   volume = {22},
   number = {11},
   pages = {995-1002},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:1329648(Journal; General Review)
10.1016/j.jnutbio.2011.05.016},
   abstract = {A review. Nutrition is the cornerstone of health; survival depends on acquiring essential nutrients, and dietary components can both prevent and promote disease. Metabolomics, the study of all small mol. metabolic products in a system, has been shown to provide a detailed snapshot of the body's processes at any particular point in time, opening up the possibility of monitoring health and disease, prevention and treatment. Metabolomics has the potential to fundamentally change clin. chem. and, by extension, the fields of nutrition, toxicol. and medicine. Technol. advances, combined with new knowledge of the human genome and gut microbiome, have made and will continue to make possible earlier, more accurate, less invasive diagnoses, all while enhancing our understanding of the root causes of disease and leading to a generation of dietary recommendations that enable optimal health. This article reviews the recent contributions of metabolomics to the fields of nutrition, toxicol. and medicine. It is expected that these fields will eventually blend together through development of new technologies in metabolomics and genomics into a new area of clin. chem.: personalized medicine. [on SciFinder(R)]},
   keywords = {review diet health genomic},
   year = {2011}
}

@article{
   author = {Mounet, F. and Lemaire-Chamley, M. and Maucourt, M. and Cabasson, C. and Giraudel, J. L. and Deborde, C. and Lessire, R. and Gallusci, P. and Bertrand, A. and Gaudillere, M. and Rothan, C. and Rolin, D. and Moing, A.},
   title = {Quantitative metabolic profiles of tomato flesh and seeds during fruit development: complementary analysis with ANN and PCA},
   journal = {Metabolomics},
   volume = {3},
   number = {3},
   pages = {273-288},
   note = {217JZ
Times Cited:33
Cited References Count:58},
   abstract = {Tomato, an essential crop in terms of economic importance and nutritional quality, is also used as a model species for all fleshy fruits and for genomics of Solanaceae. Tomato fruit quality at harvest is a direct function of its metabolite content, which in turn is a result of many physiological changes during fruit development. The aim of the work reported here was to develop a global approach to characterize changes in metabolic profiles in two interdependent tissues from the same tomato fruits. Absolute quantification data of compounds in flesh and seeds from 8 days to 45 days post anthesis (DPA) were obtained through untargeted (proton nuclear magnetic resonance, H-1-NMR) and targeted metabolic profiling (liquid chromatography with diode array detection (LC-DAD) or gas chromatography with flame ionization detection (GC-FID)). These data were analyzed with chemometric approaches. Kohonen self organizing maps (SOM) analysis of these data allowed us to combine multivariate (distribution of samples on Kohonen SOMs) and univariate information (component plane representation of metabolites) in a single analysis. This strategy confirmed published data and brought new insights on tomato flesh and seed composition, thus demonstrating its potential in metabolomics. The compositional changes were related to physiological processes occurring in each tissue. They pointed to (i) some parallel changes at early stages in relation to cell division and transitory storage of carbon, (ii) metabolites participating in the fleshy trait and (iii) metabolites involved in the specific developmental patterns of the seeds.},
   keywords = {solanum lycopersicum
fruit
seed
h-1 nmr
polar metabolites
lipids
isoprenoids
metabolic fingerprinting
rnetabolomics
amino-acid-composition
lycopersicon-esculentum
starch metabolism
biosynthesis
accumulation
pericarp
tissue
lipids
chromatography
carotenoids},
   year = {2007}
}

@article{
   author = {Nicholson, J. K. and Holmes, E. and Wilson, I. D.},
   title = {Gut microorganisms, mammalian metabolism and personalized health care},
   journal = {Nature Reviews Microbiology},
   volume = {3},
   number = {5},
   pages = {431-438},
   note = {920WQ
Times Cited:247
Cited References Count:66},
   abstract = {The mammalian gut microbiota interact extensively with the host through metabolic exchange and co-metabolism of substrates. Such metabolome-metabolome interactions are poorly understood, but might be implicated in the aetiology of many human diseases. In this paper, we assess the importance of the gut microbota in influencing the disposition, fate and toxicity of drugs in the host, and conclude that appropriate consideration of individual human gut microbial activities will be a necessary part of future personalized health-care paradigms.},
   keywords = {performance liquid-chromatography
flight mass-spectrometry
intestinal microflora
biomarker identification
gastrointestinal-tract
drug toxicity
fecal flora
rat urine
germ-free
metabonomics},
   year = {2005}
}

@article{
   author = {Nielsen, N. P. V. and Carstensen, J. M. and Smedsgaard, J.},
   title = {Aligning of single and multiple wavelength chromatographic profiles for chemometric data analysis using correlation optimised warping},
   journal = {Journal of Chromatography A},
   volume = {805},
   number = {1-2},
   pages = {17-35},
   note = {Zp037
Times Cited:277
Cited References Count:14},
   abstract = {The use of chemometric data processing is becoming an important part of modern chromatography. Most chemometric analyses are performed on reduced data sets using areas of selected peaks detected in the chromatograms, which means a loss of data and introduces the problem of extracting peak data from the chromatographic profiles. These disadvantages can be overcome by using the entire chromatographic data matrix in chemometric analyses, but it is necessary to align the chromatograms, as small unavoidable differences in experimental conditions causes minor changes and drift. Previous aligning methods either fail to utilise the entire data matrix or rely on peak detection, thus having the same limitations as the commonly used chemometric procedures. The method presented uses the entire chromatographic data matrices and does not require any preprocessing e.g., peak detection. It relies on piecewise linear correlation optimised warping (COW) using two input parameters which can be estimated from the observed peak width. COW is demonstrated on constructed single trace chromatograms and on single and multiple wavelength chromatograms obtained from HPLC diode detection analyses of fungal extracts(1). (C) 1998 Elsevier Science B.V.},
   keywords = {chemometrics
correlation optimised warping
pattern-recognition
liquid-chromatography},
   year = {1998}
}

@article{
   author = {Pearson, Karl},
   title = {On Lines and Planes of Closest Fit to Systems of Points in Space},
   journal = {Philosophical Magazine},
   volume = {2},
   number = {6},
   pages = {14},
   year = {1901}
}

@article{
   author = {Powers, Robert},
   title = {NMR metabolomics and drug discovery},
   journal = {Magnetic Resonance in Chemistry},
   volume = {47},
   pages = {S2-S11},
   note = {10.1002/mrc.2461},
   year = {2009}
}

@article{
   author = {Ramautar, R. and Demirci, A. and de Jong, G. J.},
   title = {Capillary electrophoresis in metabolomics},
   journal = {Trac-Trends in Analytical Chemistry},
   volume = {25},
   number = {5},
   pages = {455-466},
   note = {044IK
Times Cited:40
Cited References Count:57},
   abstract = {This article describes the potential of capillary electrophoresis (CE) in metabolomics, which concerns the comprehensive analysis of endogenous low-molecular weight compounds in a biological system. Consequently, metabolomic methods are often developed to separate and to detect as many endogenous metabolites as possible in a single analysis. CE is a very powerful technique for this type of profiling.
We demonstrate the applicability of CE in different fields of metabolomics research. We show illustrative clinical, bacterial and plant examples and stress the information that CE systems obtain.
We distinguish between targeted and non-targeted metabolomic studies in the bacterial and plant sections. We discuss general aspects of sample preparation of CE for biological samples, and pay special attention to the potential of CE-mass spectrometry in metabolomics.
We also discuss future developments with regard to sample preparation and the use of hyphenated systems. (c) 2006 Elsevier Ltd. All rights reserved.},
   keywords = {bacterial
capillary electrophoresis
ce
clinical
mass spectrometry
metabolomics
ms
plant
ionization-mass-spectrometry
solid-phase extraction
indirect uv detection
zone electrophoresis
systems biology
organic-acids
amino-acids
liquid-chromatography
metabolite analysis
nmr-spectroscopy},
   year = {2006}
}

@article{
   author = {Rannar, S. and Lindgren, F. and Geladi, P. and Wold, S.},
   title = {A Pls Kernel Algorithm for Data Sets with Many Variables and Fewer Objects .1. Theory and Algorithm},
   journal = {Journal of Chemometrics},
   volume = {8},
   number = {2},
   pages = {111-125},
   note = {Nc517
Times Cited:116
Cited References Count:24},
   abstract = {A fast PLS regression algorithm dealing with large data matrices with many variables (K) and fewer objects (N) is presented. For such data matrices the classical algorithm is computer-intensive and memory-demanding. Recently, Lindgren et al. (J. Chemometrics, 7, 45-49 (1993)) developed a quick and efficient kernel algorithm for the case with many objects and few variables. The present paper is focused on the opposite case, i.e. many variables and fewer objects. A kernel algorithm is presented based on eigenvectors to the 'kernel' matrix XX(T)YY(T), which is a square, non-symmetric matrix of size N x N, where N is the number of objects. Using the kernel matrix and the association matrices XX(T) (N x N) and YY(T) (N x N), it is possible to calculate all score and loading vectors and hence conduct a complete PLS regression including diagnostics such as R2. This is done without returning to the original data matrices X and Y. The algorithm is presented in equation form, with proofs of some new properties and as MATLAB code.},
   keywords = {pls regression algorithm
kernel
many-variable data sets
squares
regression},
   year = {1994}
}

@article{
   author = {Sadykov, M. R. and Zhang, B. and Halouska, S. and Nelson, J. L. and Kreimer, L. W. and Zhu, Y. F. and Powers, R. and Somerville, G. A.},
   title = {Using NMR Metabolomics to Investigate Tricarboxylic Acid Cycle-dependent Signal Transduction in Staphylococcus epidermidis},
   journal = {Journal of Biological Chemistry},
   volume = {285},
   number = {47},
   pages = {36616-36624},
   note = {679FE
Times Cited:9
Cited References Count:71},
   abstract = {Staphylococcus epidermidis is a skin-resident bacterium and a major cause of biomaterial-associated infections. The transition from residing on the skin to residing on an implanted biomaterial is accompanied by regulatory changes that facilitate bacterial survival in the new environment. These regulatory changes are dependent upon the ability of bacteria to "sense" environmental changes. In S. epidermidis, disparate environmental signals can affect synthesis of the biofilm matrix polysaccharide intercellular adhesin (PIA). Previously, we demonstrated that PIA biosynthesis is regulated by tricarboxylic acid (TCA) cycle activity. The observations that very different environmental signals result in a common phenotype (i.e. increased PIA synthesis) and that TCA cycle activity regulates PIA biosynthesis led us to hypothesize that S. epidermidis is "sensing" disparate environmental signals through the modulation of TCA cycle activity. In this study, we used NMR metabolomics to demonstrate that divergent environmental signals are transduced into common metabolomic changes that are "sensed" by metabolite-responsive regulators, such as CcpA, to affect PIA biosynthesis. These data clarify one mechanism by which very different environmental signals cause common phenotypic changes. In addition, due to the frequency of the TCA cycle in diverse genera of bacteria and the intrinsic properties of TCA cycle enzymes, it is likely the TCA cycle acts as a signal transduction pathway in many bacteria.},
   keywords = {intercellular adhesin production
carbon catabolite repression
virulence gene-expression
biofilm formation
bacillus-subtilis
sigma(b) regulon
iron limitation
sigb operon
aureus
growth},
   year = {2010}
}

@article{
   author = {Shao, J.},
   title = {Linear-Model Selection by Cross-Validation},
   journal = {Journal of the American Statistical Association},
   volume = {88},
   number = {422},
   pages = {486-494},
   note = {Ld680
Times Cited:444
Cited References Count:20},
   abstract = {We consider the problem of selecting a model having the best predictive ability among a class of linear models.  The popular leave-one-out cross-validation method, which is asymptotically equivalent to many other model selection methods such as the Akaike information criterion (AIC), the C(p), and the bootstrap, is asymptotically inconsistent in the sense that the probability of selecting the model with the best predictive ability does not converge to 1 as the total number of observations n --> infinity. We show that the inconsistency of the leave-one-out cross-validation can be rectified by using a leave-n(v)-out cross-validation with n(v), the number of observations reserved for validation, satisfying n(v)/n --> 1 as n --> infinity. This is a somewhat shocking discovery, because n(v)/n --> 1 is totally opposite to the popular leave-one-out recipe in cross-validation. Motivations, justifications, and discussions of some practical aspects of the use of the leave-n(v)-out cross-validation method are provided, and results from a simulation study are presented.},
   keywords = {balanced incomplete
consistency
data splitting
model assessment
monte carlo
prediction
prediction rule
error rate
criterion
choice
cp},
   year = {1993}
}

@article{
   author = {Sjoblom, J. and Svensson, O. and Josefson, M. and Kullberg, H. and Wold, S.},
   title = {An evaluation of orthogonal signal correction applied to calibration transfer of near infrared spectra},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {44},
   number = {1-2},
   pages = {229-244},
   note = {155LW
Times Cited:157
Cited References Count:14},
   abstract = {Orthogonal signal correction (OSC) is a technique for pre-processing of, for example, NIR-spectra before they are subjected to a multivariate calibration. With OSC the X-matrix is corrected by a subtraction of variation that is orthogonal to the calibration Y-matrix. This correction can then be applied to new spectra that are going to be used in predictions. The aim of this study is to investigate if the OSC transform makes the spectra less dependent of instrument variation. This may result in easier calibration model transfer between different instruments without creating or re-analysing the whole calibration sample set. OSC was applied to MR-spectra that were used in a calibration for the water content in a pharmaceutical product. Partial Least Squares calibrations were then compared to other calibration models with uncorrected spectra, models with spectra subjected to multiplicative signal correction, and a number of other transfer methods. The performance of OSC was on the same level as for piece-wise direct standardisation and spectral offset correction for each individual instrument and PLS-models with both instruments included. (C) 1998 Elsevier Science B.V. All rights reserved.},
   keywords = {chemometrics
spectroscopy
spectrometry
near infrared
orthogonal signal correction
calibration transfer
nir
diffuse reflectance
multivariate instrument standardization},
   year = {1998}
}

@article{
   author = {Skov, T. and van den Berg, F. and Tomasi, G. and Bro, R.},
   title = {Automated alignment of chromatographic data},
   journal = {Journal of Chemometrics},
   volume = {20},
   number = {11-12},
   pages = {484-497},
   note = {175ZC
Times Cited:75
Cited References Count:12},
   abstract = {This paper focuses on the practical aspects and implications of preprocessing chromatographic data to correct for undesirable time-shifts. An approach to automate the alignment of chromatographic data based on peak alignment or warping is proposed. This approach deals with selection of the required parameters including selection of reference sample to warp towards, and chooses warping settings based on a new evaluation criterion for goodness of correction. The new criterion aims at quantifying goodness of alignment while at the same time penalising significant shape or area-changes in the warped peaks. The entire selection procedure is automated using a discrete-coordinates simplex-like optimisation routine. Examples with simulated chromatographic data, GC-FID and HPLC-Fluorescence measurement series illustrate the potential of using this automated alignment tool. (C) Copyright 2007 John Wiley & Sons, Ltd.},
   keywords = {automated alignment
correlation optimised warping
peak area preservation
chromatographic data
optimisation
mass-spectrometry
time},
   year = {2006}
}

@article{
   author = {Smilde, A. K. and van der Werf, M. J. and Bijlsma, S. and van der Werff-van-der Vat, B. J. C. and Jellema, R. H.},
   title = {Fusion of mass spectrometry-based metabolomics data},
   journal = {Analytical Chemistry},
   volume = {77},
   number = {20},
   pages = {6729-6736},
   note = {977ET
Times Cited:63
Cited References Count:39},
   abstract = {A general method is presented for combining mass spectrometry-based metabolomics data. Such data are becoming more and more abundant, and proper tools for fusing these types of data sets are needed. Fusion of metabolomics data leads to a comprehensive view on the metabolome of an organism or biological system. The ideas presented draw upon established techniques in data analysis. Hence, they are also widely applicable to other types of X-omics data provided there is a proper pretreatment of the data. These issues are discussed using a real-life metabolomics data set from a microbial fermentation process.},
   keywords = {multivariate curve resolution
covariates regression-models
multiblock component
systems biology
pls-regression
selection
metabolites
complexity
tool},
   year = {2005}
}

@article{
   author = {Stone, M.},
   title = {An Asymptotic Equivalence of Choice of Model by Cross-Validation and Akaike’s Criterion  },
   journal = { J. R. Stat. Soc., B},
   volume = {39},
   number = {1},
   pages = {44-47},
   year = {1977}
}

@misc{
   author = {Sun, Liang and Ji, Shuiwang and Ye, Jieping},
   title = {A least squares formulation for a class of generalized eigenvalue problems in machine learning},
   publisher = {ACM},
   pages = {977-984},
   year = {2009}
}

@article{
   author = {Sysi-Aho, M. and Katajamaa, M. and Yetukuri, L. and Oresic, M.},
   title = {Normalization method for metabolomics data using optimal selection of multiple internal standards},
   journal = {Bmc Bioinformatics},
   volume = {8},
   note = {154CC
Times Cited:38
Cited References Count:22},
   abstract = {Background: Success of metabolomics as the phenotyping platform largely depends on its ability to detect various sources of biological variability. Removal of platform-specific sources of variability such as systematic error is therefore one of the foremost priorities in data preprocessing. However, chemical diversity of molecular species included in typical metabolic profiling experiments leads to different responses to variations in experimental conditions, making normalization a very demanding task.
Results: With the aim to remove unwanted systematic variation, we present an approach that utilizes variability information from multiple internal standard compounds to find optimal normalization factor for each individual molecular species detected by metabolomics approach (NOMIS). We demonstrate the method on mouse liver lipidomic profiles using Ultra Performance Liquid Chromatography coupled to high resolution mass spectrometry, and compare its performance to two commonly utilized normalization methods: normalization by 12 norm and by retention time region specific standard compound profiles. The NOMIS method proved superior in its ability to reduce the effect of systematic error across the full spectrum of metabolite peaks. We also demonstrate that the method can be used to select best combinations of standard compounds for normalization.
Conclusion: Depending on experiment design and biological matrix, the NOMIS method is applicable either as a one-step normalization method or as a two-step method where the normalization parameters, influenced by variabilities of internal standard compounds and their correlation to metabolites, are first calculated from a study conducted in repeatability conditions. The method can also be used in analytical development of metabolomics methods by helping to select best combinations of standard compounds for a particular biological matrix and analytical platform.},
   keywords = {mass-spectrometry
profile data
phenotype
strategy},
   year = {2007}
}

@article{
   author = {Tang, Jane},
   title = {Microbial metabolomics},
   journal = {Curr. Genomics},
   volume = {12},
   number = {6},
   pages = {391-403},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:1322933(Journal; General Review)
10.2174/138920211797248619},
   abstract = {Microbial metabolomics constitutes an integrated component of systems biol. By studying the complete set of metabolites within a microorganism and monitoring the global outcome of interactions between its development processes and the environment, metabolomics can potentially provide a more accurate snap shot of the actual physiol. state of the cell. Recent advancement of technologies and post-genomic developments enable the study and anal. of metabolome. This unique contribution resulted in many scientific disciplines incorporating metabolomics as one of their "omics" platforms. This review focuses on metabolomics in microorganisms and utilizes selected topics to illustrate its impact on the understanding of systems microbiol. [on SciFinder(R)]},
   keywords = {review metabolomics systems microbiol},
   year = {2011}
}

@article{
   author = {Tapp, H. S. and Kemsley, E. K.},
   title = {Notes on the practical utility of OPLS},
   journal = {Trac-Trends in Analytical Chemistry},
   volume = {28},
   number = {11},
   pages = {1322-1327},
   note = {534SW
Times Cited:5
Cited References Count:60},
   abstract = {This article concerns two chemometric modeling methods - the well-known partial least squares regression and the comparatively recently-devised orthogonal projections to latent structures (OPLS). We discuss their similarities and differences with a focus on the usage of OPLS in the analytical-chemistry literature. (C) 2009 Elsevier Ltd. All rights reserved.},
   keywords = {partial least squares, pls
orthogonal projections to latent structures, opls
performance equivalence
interpretation
correlation
covariance
total correlation spectroscopy
correlation nmr-spectroscopy
human metabolic phenotypes
least-squares regression
microbiome mouse model
orthogonal projections
h-1-nmr spectroscopy
induced hepatotoxicity
discriminant-analysis
gut microbiota},
   year = {2009}
}

@article{
   author = {Teahan, Orla and Gamble, Simon and Holmes, Elaine and Waxman, Jonathan and Nicholson, Jeremy K. and Bevan, Charlotte and Keun, Hector C.},
   title = {Impact of Analytical Bias in Metabonomic Studies of Human Blood Serum and Plasma},
   journal = {Anal. Chem.},
   volume = {78},
   number = {13},
   pages = {4307-4318},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2006:456767(Journal)
10.1021/ac051972y},
   abstract = {Concurrent with the explosion in the no. of publications reporting biomarker discovery by profiling technologies, such as proteomics and pattern recognition, has been the increase in evidence highlighting the susceptibility of these approaches to anal. and exptl. bias. The work presented here addresses these timely issues by delivering a detailed characterization of the effect of common sources of bias in clin. studies on serum and plasma profiles generated by a key technol. in metabonomics, NMR spectroscopy. Specifically, differences in compn. when blood samples were collected onto and in the absence of ice, over a series of serum-clot contact times, the stability of NMR-prepd. samples over time and the effect on the metabolic profile of freeze-thawing were examd. While differences between individuals were far greater than variation from any other exptl. factor, each of the conditions examd. did cause slight alterations to the NMR profile that could produce a systematic bias. Variation due to clotting time caused changes in energy metabolites, which were delayed by ice with no other spectral effects. Room-temp. stability and hence NMR spectral repeatability were high (<1% intrasample variation). Higher mol. wt. species such as lipoproteins were more susceptible to the variations present in the examd. factors. These observations have implications for profiling study design, and hence, the authors' results form a new and valuable resource for those attempting clin. metabolic profiling, for regulatory agencies involved in the licensing of clin. tests and in the generation of international reporting stds. for metabonomics. [on SciFinder(R)]},
   keywords = {analytical bias metabonomics serum plasma},
   year = {2006}
}

@article{
   author = {Tomasi, G. and van den Berg, F. and Andersson, C.},
   title = {Correlation optimized warping and dynamic time warping as preprocessing methods for chromatographic data},
   journal = {Journal of Chemometrics},
   volume = {18},
   number = {5},
   pages = {231-241},
   note = {853MH
Times Cited:191
Cited References Count:24},
   abstract = {Two different algorithms for time-alignment as a preprocessing step in linear factor models are studied. Correlation optimized warping and dynamic time warping are both presented in the literature as methods that can eliminate shift-related artifacts from measurements by correcting a sample vector towards a reference. In this study both the theoretical properties and the practical implications of using signal warping as preprocessing for chromatographic data are investigated. The connection between the two algorithms is also discussed. The findings are illustrated by means of a case study of principal component analysis on a real data set, including manifest retention time artifacts, of extracts from coffee samples stored under different packaging conditions for varying storage times. We concluded that for the data presented here dynamic time warping with rigid slope constraints and correlation optimized warping are superior to unconstrained dynamic time warping; both considerably simplify interpretation of the factor model results. Unconstrained dynamic time warping was found to be too flexible for this chromatographic data set, resulting in an overcompensation of the observed shifts and suggesting the unsuitability of this preprocessing method for this type of signals. Copyright (C) 2004 John Wiley Sons, Ltd.},
   keywords = {dtw
cow
warping
retention time shift
pca
connected word recognition
mass-spectrometry
speech recognition
algorithm},
   year = {2004}
}

@article{
   author = {Trethewey, R. N.},
   title = {Gene discovery via metabolic profiling},
   journal = {Current Opinion in Biotechnology},
   volume = {12},
   number = {2},
   pages = {135-138},
   note = {418VY
Times Cited:46
Cited References Count:25},
   abstract = {Biochemical analysis is adding a new dimension to the process of gene discovery. Two major developments have recently taken place in the emerging science of biochemical genomics. The first is an approach that uses a combination of tagged fusion proteins and simple pooling strategies in order to efficiently and directly assign biochemical function to the products of open reading frames (ORFs) expressed in yeast. The second is the application of metabolic profiling technologies to the study of mutant and transgenic plants. The latter approach has the potential not only to discover novel genes but also to ascribe a function to them in the context of the organism from which they are derived.},
   keywords = {plant functional genomics
mass-spectrometry
arabidopsis-thaliana
yeast invertase
inborn-errors
potato-tuber
expression
proteomics
microarrays
glucokinase},
   year = {2001}
}

@article{
   author = {Trygg, J. and Wold, S.},
   title = {Orthogonal projections to latent structures (O-PLS)},
   journal = {Journal of Chemometrics},
   volume = {16},
   number = {3},
   pages = {119-128},
   note = {528FP
Times Cited:440
Cited References Count:19},
   abstract = {A generic preprocessing method for multivariate data, called orthogonal projections to latent structures (O-PLS), is described. O-PLS removes variation from X (descriptor variables) that is not correlated to Y (property variables, e.g. yield, cost or toxicity). In mathematical terms this is equivalent to removing systematic variation in X that is orthogonal to Y. In an earlier paper, Wold et al. (Chemometrics Intell, Lab. Syst. 1998; 44:175-185) described orthogonal signal correction (OSC). In this paper a method with the same objective but with different means is described. The proposed O-PLS method analyzes the variation explained in each PLS component. The non-correlated systematic variation in X is removed, making interpretation of the resulting PLS model easier and with the additional benefit that the non-correlated variation itself can be analyzed further. As an example, near-infrared (NIR) reflectance spectra of wood chips were analyzed. Applying O-PLS resulted in reduced model complexity with preserved prediction ability, effective removal of noncorrelated variation in X and, not least, improved interpretational ability of both correlated and noncorrelated variation in the NIR spectra. Copyright (C) 2002 John Wiley Sons, Ltd.},
   keywords = {orthogonal projections to latent structures (o-pls)
orthogonal signal correction (osc)
nipals pls
multivariate data analysis
calibration
preprocessing
near-infrared spectra
signal correction
calibration transfer
regression-models},
   year = {2002}
}

@article{
   author = {Tyagi, Satyanand and Raghvendra and Singh, Usha and Kalra, Taruna and Munjal, Kavita},
   title = {Applications of Metabolomics - a systematic study of the unique chemical fingerprints: an overview},
   journal = {Int. J. Pharm. Sci. Rev. Res.},
   volume = {3},
   number = {1},
   pages = {83-86},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2010:883322(Journal; General Review; Online Computer File)},
   abstract = {A review. Metabolomics is a newborn cousin to genomics and proteomics. Specifically, metabolomics involves the rapid, high throughput characterization of the small mol. metabolites found in an organism. Since the metabolome is closely tied to the genotype of an organism, its physiol. and its environment, metabolomics offers a unique opportunity to look at genotype-phenotype as well as genotype-envirotype relationships. Metabolomics is increasingly being used in a variety of health applications including pharmacol., pre-clin. drug trials, toxicol., transplant monitoring, newborn screening and clin. chem. However, a key limitation to metabolomics is the fact that the human metabolome is not at all well characterized. The growing field called metabolomics detects and quantifies the low mol. wt. mols., known as metabolites (constituents of the metabolome), produced by active, living cells under different conditions and times in their life cycles. NMR is playing an important role in metabolomics because of its ability to observe mixts. of small mols. in living cells or in cell exts. The words 'Metabolomics' and 'Metabonomics' are often used interchangeably, though a consensus is beginning to develop as to the specific meaning of each. The goals of metabolomics are to catalog and quantify the myriad small mols. found in biol. fluids under different conditions. Metabonomics is the study of how the metabolic profile of a complex biol. system changes in response to stresses like disease, toxic exposure, or dietary change. In the present article, we have concd. on clin. and other relevant applications of metabolomics. The aim of present article is to provide in depth knowledge about clin. utility of metabolomics in current clin. scenario. [on SciFinder(R)]},
   keywords = {review metabolite metabolomics chem fingerprinting NMR spectroscopy},
   year = {2010}
}

@article{
   author = {van den Berg, R. A. and Hoefsloot, H. C. J. and Westerhuis, J. A. and Smilde, A. K. and van der Werf, M. J.},
   title = {Centering, scaling, and transformations: improving the biological information content of metabolomics data},
   journal = {Bmc Genomics},
   volume = {7},
   note = {071WD
Times Cited:178
Cited References Count:27},
   abstract = {Background: Extracting relevant biological information from large data sets is a major challenge in functional genomics research. Different aspects of the data hamper their biological interpretation. For instance, 5000-fold differences in concentration for different metabolites are present in a metabolomics data set, while these differences are not proportional to the biological relevance of these metabolites. However, data analysis methods are not able to make this distinction. Data pretreatment methods can correct for aspects that hinder the biological interpretation of metabolomics data sets by emphasizing the biological information in the data set and thus improving their biological interpretability.
Results: Different data pretreatment methods, i.e. centering, autoscaling, pareto scaling, range scaling, vast scaling, log transformation, and power transformation, were tested on a real-life metabolomics data set. They were found to greatly affect the outcome of the data analysis and thus the rank of the, from a biological point of view, most important metabolites. Furthermore, the stability of the rank, the influence of technical errors on data analysis, and the preference of data analysis methods for selecting highly abundant metabolites were affected by the data pretreatment method used prior to data analysis.
Conclusion: Different pretreatment methods emphasize different aspects of the data and each pretreatment method has its own merits and drawbacks. The choice for a pretreatment method depends on the biological question to be answered, the properties of the data set and the data analysis method selected. For the explorative analysis of the validation data set used in this study, autoscaling and range scaling performed better than the other pretreatment methods. That is, range scaling and autoscaling were able to remove the dependence of the rank of the metabolites on the average concentration and the magnitude of the fold changes and showed biologically sensible results after PCA (principal component analysis).
In conclusion, selecting a proper data pretreatment method is an essential step in the analysis of metabolomics data and greatly affects the metabolites that are identified to be the most important.},
   keywords = {gas chromatography/mass spectrometry
microbial metabolomics
heteroscedastic noise
microarray data
degradation
selection},
   year = {2006}
}

@article{
   author = {van der Greef, J. and Smilde, A. K.},
   title = {Symbiosis of chemometrics and metabolomics: past, present, and future},
   journal = {Journal of Chemometrics},
   volume = {19},
   number = {5-7},
   pages = {376-386},
   note = {012ZA
Times Cited:42
Cited References Count:84},
   abstract = {Metabolomics is a growing area in the field of systems biology. Metabolomics has already a long history and also the connection of metabolomics with chemometrics goes back some time. This review discusses the symbiosis of metabolomics and chemometrics with emphasis on the medical domain, puts the combination of the two in historical perspective and tries to give ideas for future research. Copyright (C) 2006 John Wiley & Sons, Ltd.},
   keywords = {metabolomics
metabolic profiling
systems biology
pattern recognition
biorhythms
dynamic diseases
connectivity
ionization mass-spectrometry
principal component analysis
gas-chromatography
systems biology
pattern-recognition
multicomponent therapeutics
interpreting correlations
field-desorption
models
profiles},
   year = {2005}
}

@article{
   author = {Veselkov, Kirill A. and Lindon, John C. and Ebbels, Timothy M. D. and Crockford, Derek and Volynkin, Vladimir V. and Holmes, Elaine and Davies, David B. and Nicholson, Jeremy K.},
   title = {Recursive Segment-Wise Peak Alignment of Biological 1H NMR Spectra for Improved Metabolic Biomarker Recovery},
   journal = {Anal. Chem. (Washington, DC, U. S.)},
   volume = {81},
   number = {1},
   pages = {56-66},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2008:1454275(Journal)
10.1021/ac8011544},
   abstract = {Chem. shift variation in small-mol. 1H NMR signals of biofluids complicates biomarker information recovery in metabonomic studies when using multivariate statistical and pattern recognition tools. Current peak realignment methods are generally time-consuming or align major peaks at the expense of minor peak shift accuracy. The authors present a novel recursive segment-wise peak alignment (RSPA) method to reduce variability in peak positions across the multiple 1H NMR spectra used in metabonomic studies. The method refines a segmentation of ref. and test spectra in a top-down fashion, sequentially subdividing the initial larger segments, as required, to improve the local spectral alignment. The authors also describe a general procedure that allows robust comparison of realignment quality of various available methods for a range of peak intensities. The RSPA method is illustrated with respect to 140 1H NMR rat urine spectra from a caloric restriction study and is compared with several other widely used peak alignment methods. The authors demonstrate the superior performance of the RSPA alignment over a wide range of peaks and its capacity to enhance interpretability and robustness of multivariate statistical tools. The approach is widely applicable for NMR-based metabolic studies and is potentially suitable for many other types of data sets such as chromatog. profiles and MS data. [on SciFinder(R)]},
   keywords = {recursive segment wise peak alignment biomol NMR spectra biomarker},
   year = {2009}
}

@article{
   author = {Vinayavekhin, Nawaporn and Homan, Edwin A. and Saghatelian, Alan},
   title = {Exploring Disease through Metabolomics},
   journal = {ACS Chem. Biol.},
   volume = {5},
   number = {1},
   pages = {91-103},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2010:57013(Journal; General Review)
10.1021/cb900271r},
   abstract = {A review. Metabolomics approaches provide an anal. of changing metabolite levels in biol. samples. In the past decade, tech. advances have spurred the application of metabolomics in a variety of diverse research areas spanning basic, biomedical, and clin. sciences. In particular, improvements in instrumentation, data anal. software, and the development of metabolite databases have accelerated the measurement and identification of metabolites. Metabolomics approaches have been applied to a no. of important problems, which include the discovery of biomarkers as well as mechanistic studies aimed at discovering metabolites or metabolic pathways that regulate cellular and physiol. processes. By providing access to a portion of biomol. space not covered by other profiling approaches (e.g., proteomics and genomics), metabolomics offers unique insights into small mol. regulation and signaling in biol. In the following review, the authors look at the integration of metabolomics approaches in different areas of basic and biomedical research, and try to point out the areas in which these approaches have enriched in the understanding of cellular and physiol. biol., esp. within the context of pathways linked to disease. [on SciFinder(R)]},
   keywords = {review disease metabolomics metabolite biomarker biomol},
   year = {2010}
}

@article{
   author = {Viswanadhan, Vellarkad N. and Rajesh, Hariharan and Balaji, Vitukudi N.},
   title = {Atom Type Preferences, Structural Diversity, and Property Profiles of Known Drugs, Leads, and Nondrugs: A Comparative Assessment},
   journal = {ACS Comb. Sci.},
   volume = {13},
   number = {3},
   pages = {327-336},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2011:484733(Journal; Online Computer File)
10.1021/co2000168},
   abstract = {A new characterization of known drug, lead, and representative nondrug databases was performed taking into account several properties at the at. and mol. levels. This characterization included atom type preferences, intrinsic structural diversity (Atom Type Diversity, ATD), and other well-known physicochem. properties, as an approach for rapid assessment of drug likeness for small mol. libraries. To characterize ATD, an elaborate united atom classification, UALOGP (United Atom Log P), with 148 atom types, was developed along with assocd. at. physicochem. parameters. This classification also enabled an anal. of atom type and physicochem. property distributions (for calcd. log P, molar refractivity, mol. wt., total atom count, and ATD) of drug, lead, and nondrug databases, a reassessment of the Ro5 (Rule of Five) and GVW (Ghose-Viswanadhan-Wendoloski) criteria, and development of new criteria and ranges more accurately reflecting the chem. space occupied by small mol. drugs. A relative drug likeness parameter was defined for atom types in drugs, identifying the most preferred types. The present work demonstrates that drug mols. are constitutionally more diverse relative to nondrugs, while being less diverse than leads. [on SciFinder(R)]},
   keywords = {bioinformatics chemoinformatics drug discovery physicochem property combinatorial library database},
   year = {2011}
}

@article{
   author = {Vu, T. N. and Valkenborg, D. and Smets, K. and Verwaest, K. A. and Dommisse, R. and Lemiere, F. and Verschoren, A. and Goethals, B. and Laukens, K.},
   title = {An integrated workflow for robust alignment and simplified quantitative analysis of NMR spectrometry data},
   journal = {Bmc Bioinformatics},
   volume = {12},
   note = {848IG
Times Cited:0
Cited References Count:24},
   abstract = {Background: Nuclear magnetic resonance spectroscopy (NMR) is a powerful technique to reveal and compare quantitative metabolic profiles of biological tissues. However, chemical and physical sample variations make the analysis of the data challenging, and typically require the application of a number of preprocessing steps prior to data interpretation. For example, noise reduction, normalization, baseline correction, peak picking, spectrum alignment and statistical analysis are indispensable components in any NMR analysis pipeline.
Results: We introduce a novel suite of informatics tools for the quantitative analysis of NMR metabolomic profile data. The core of the processing cascade is a novel peak alignment algorithm, called hierarchical Cluster-based Peak Alignment (CluPA). The algorithm aligns a target spectrum to the reference spectrum in a top-down fashion by building a hierarchical cluster tree from peak lists of reference and target spectra and then dividing the spectra into smaller segments based on the most distant clusters of the tree. To reduce the computational time to estimate the spectral misalignment, the method makes use of Fast Fourier Transformation (FFT) cross-correlation. Since the method returns a high-quality alignment, we can propose a simple methodology to study the variability of the NMR spectra. For each aligned NMR data point the ratio of the between-group and within-group sum of squares (BW-ratio) is calculated to quantify the difference in variability between and within predefined groups of NMR spectra. This differential analysis is related to the calculation of the F-statistic or a one-way ANOVA, but without distributional assumptions. Statistical inference based on the BW-ratio is achieved by bootstrapping the null distribution from the experimental data.
Conclusions: The workflow performance was evaluated using a previously published dataset. Correlation maps, spectral and grey scale plots show clear improvements in comparison to other methods, and the down-to-earth quantitative analysis works well for the CluPA-aligned spectra. The whole workflow is embedded into a modular and statistically sound framework that is implemented as an R package called "speaq" ("spectrum alignment and quantitation"), which is freely available from http://code.google.com/p/speaq/.},
   keywords = {peak alignment
mass-spectrometry
chromatographic data
cross-correlation
h-1-nmr spectra
classification
metabolomics
algorithms
signals},
   year = {2011}
}

@article{
   author = {Vuckovic, Dajana},
   title = {Current trends and challenges in sample preparation for global metabolomics using liquid chromatography-mass spectrometry},
   journal = {Anal. Bioanal. Chem.},
   volume = {403},
   number = {6},
   pages = {1523-1548},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2012:676742(Journal; General Review; Online Computer File)
10.1007/s00216-012-6039-y},
   abstract = {A review. The choice of sample-prepn. method is extremely important in metabolomic studies because it affects both the obsd. metabolite content and biol. interpretation of the data. An ideal sample-prepn. method for global metabolomics should (i) be as non-selective as possible to ensure adequate depth of metabolite coverage; (ii) be simple and fast to prevent metabolite loss and/or degrdn. during the prepn. procedure and enable high-throughput; (iii) be reproducible; and (iv) incorporate a metab.-quenching step to represent true metabolome compn. at the time of sampling. Despite its importance, sample prepn. is often an overlooked aspect of metabolomics, so the focus of this review is to explore the role, challenges, and trends in sample prepn. specifically within the context of global metabolomics by liq. chromatog.-mass spectrometry (LC-MS). This review will cover the most common methods including solvent pptn. and extn., solid-phase extn. and ultrafiltration, and discuss how to improve anal. quality and metabolite coverage in metabolomic studies of biofluids, tissues, and mammalian cells. Recent developments in this field will also be critically examd., including in vivo methods, turbulent-flow chromatog., and dried blood spot sampling. [on SciFinder(R)]},
   keywords = {review metabolomics liq chromatog mass spectrometry},
   year = {2012}
}

@article{
   author = {Weckwerth, W.},
   title = {Metabolomics in systems biology},
   journal = {Annual Review of Plant Biology},
   volume = {54},
   pages = {669-689},
   note = {717MT
Times Cited:215
Cited References Count:108},
   abstract = {The primary aim of "omic" technologies is the nontargeted identification of all gene products (transcripts, proteins, and metabolites) present in a specific biological sample. By their nature, these technologies reveal unexpected properties of biological systems. A second and more challenging aspect of omic technologies is the refined analysis of quantitative dynamics in biological systems.
For metabolomics, gas and liquid chromatography coupled to mass spectrometry are well suited for coping with high sample numbers in reliable measurement times with respect to both technical accuracy and the identification and quantitation of small-molecular-weight metabolites. This potential is a prerequisite for the analysis of dynamic systems. Thus, metabolomics is a key technology for systems biology.
The aim of this review is to (a) provide an in-depth overview about metabolomic technology, (b) explore how metabolomic networks can be connected to the underlying reaction pathway structure, and (c) discuss the need to investigate integrative biochemical networks.},
   keywords = {integrative biochemical profiling
quantitative proteomics
dynamic networks
system modeling
stochastic noise
fluctuation
supercritical-fluid extraction
protein identification technology
chromatography-mass-spectrometry
crassulacean acid metabolism
gene regulatory networks
liquid-chromatography
gas-chromatography
glycolytic oscillations
functional genomics
plant-material},
   year = {2003}
}

@article{
   author = {Wentzell, P. D. and Andrews, D. T. and Hamilton, D. C. and Faber, K. and Kowalski, B. R.},
   title = {Maximum likelihood principal component analysis},
   journal = {Journal of Chemometrics},
   volume = {11},
   number = {4},
   pages = {339-366},
   note = {Xl957
Times Cited:74
Cited References Count:22},
   abstract = {The theoretical principles and practical implementation of a new method for multivariate data analysis, maximum likelihood principal component analysis (MLPCA), are described. MLCPA is an analog to principal component analysis (PCA) that incorporates information about measurement errors to develop PCA models that are optimal in a maximum likelihood sense. The theoretical foundations of MLPCA are initially established using a regression model and extended to the framework of PCA and singular value decomposition (SVD). An efficient and reliable algorithm based on an alternating regression method is described. Generalization of the algorithm allows its adaptation to cases of correlated errors provided that the error covariance matrix is known. Models with intercept terms can also be accommodated. Simulated data and near-infrared spectra, with a variety of error structures, are used to evaluate the performance of the new algorithm. Convergence times depend on the error structure but are typically around a few minutes. In all cases, models determined by MLPCA are found to be superior to those obtained by PCA when non-uniform error distributions are present, although the level of improvement depends on the error structure of the particular data set. (C) 1997 by John Wiley & Sons, Ltd.},
   keywords = {principal component analysis
maximum likelihood
measurement errors
multivariate analysis
near-infrared spectroscopy
errors in variables
common-factor-analysis
least-squares
weights
model},
   year = {1997}
}

@article{
   author = {Werth, M. T. and Halouska, S. and Shortridge, M. D. and Zhang, B. and Powers, R.},
   title = {Analysis of metabolomic PCA data using tree diagrams},
   journal = {Analytical Biochemistry},
   volume = {399},
   number = {1},
   pages = {58-63},
   note = {565NG
Times Cited:3
Cited References Count:33},
   abstract = {Large amounts of data from high-throughput metabolomic experiments are commonly visualized using a principal component analysis (PCA) two-dimensional scores plot. The question of the similarity or difference between multiple metabolic states then becomes a question of the degree of overlap between their respective data point clusters in principal component (PC) scores space. A qualitative visual inspection of the clustering pattern in PCA scores plots is a common protocol. This article describes the application of tree diagrams and bootstrapping techniques for an improved quantitative analysis of metabolic PCA data clustering. Our PCAtoTree program creates a distance matrix with 100 bootstrap steps that describes the separation of all clusters in a metabolic data set. Using accepted phylogenetic software, the distance matrix resulting from the various metabolic states is organized into a phylogenetic-like tree format, where bootstrap values >= 50 indicate a statistically relevant branch separation. PCAtoTree analysis of two previously published data sets demonstrates the improved resolution of metabolic state differences using tree diagrams. In addition, for metabolomic studies of large numbers of different metabolic states, the tree format provides a better description of similarities and differences between each metabolic state. The approach is also tolerant of sample size variations between different metabolic states. (C) 2009 Elsevier Inc. All rights reserved.},
   keywords = {metabolomics
tree diagrams
principal component analysis
bootstrap analysis
nmr
phylogenetic trees
nmr metabolomics
metabonomics
networks
drug
construction
discovery
bootstrap},
   year = {2010}
}

@article{
   author = {Westerhuis, J. A. and Hoefsloot, H. C. J. and Smit, S. and Vis, D. J. and Smilde, A. K. and van Velzen, E. J. J. and van Duijnhoven, J. P. M. and van Dorsten, F. A.},
   title = {Assessment of PLSDA cross validation},
   journal = {Metabolomics},
   volume = {4},
   number = {1},
   pages = {81-89},
   note = {257NY
Times Cited:122
Cited References Count:27},
   abstract = {Classifying groups of individuals based on their metabolic profile is one of the main topics in metabolomics research. Due to the low number of individuals compared to the large number of variables, this is not an easy task. PLSDA is one of the data analysis methods used for the classification. Unfortunately this method eagerly overfits the data and rigorous validation is necessary. The validation however is far from straightforward. Is this paper we will discuss a strategy based on cross model validation and permutation testing to validate the classification models. It is also shown that too optimistic results are obtained when the validation is not done properly. Furthermore, we advocate against the use of PLSDA score plots for inference of class differences.},
   keywords = {cross model validation
permutation testing
classification
plsda
statistical validation
variable selection
model validation
metabolomics
classification
chemometrics
metabonomics
calibration
genomics},
   year = {2008}
}

@article{
   author = {Westerhuis, J. A. and Kourti, T. and MacGregor, J. F.},
   title = {Analysis of multiblock and hierarchical PCA and PLS models},
   journal = {Journal of Chemometrics},
   volume = {12},
   number = {5},
   pages = {301-321},
   note = {128MU
Times Cited:184
Cited References Count:25},
   abstract = {Multiblock and hierarchical PCA and PLS methods have been proposed in the recent literature in order to improve the interpretability of multivariate models. They have been used in cases where the number of variables is large and additional information is available for blocking the variables into conceptually meaningful blocks. In this paper we compare these methods from a theoretical or algorithmic viewpoint using a common notation and illustrate their differences with several case studies. Undesirable properties of some of these methods, such as convergence problems or loss of data information due to deflation procedures, are pointed out and corrected where possible. It is shown that the objective function of the hierarchical PCA and hierarchical PLS methods is not clear and the corresponding algorithms may converge to different solutions depending on the initial guess of the super score. It is also shown that the results of consensus PCA (CPCA) and multiblock PLS (MBPLS) can be calculated from the standard PCA and PLS methods when the same variable scalings are applied for these methods. The standard PCA and PLS methods require less computation and give better estimation of the scores in the case of missing data. It is therefore recommended that in cases where the variables can be separated into meaningful blocks, the standard PCA and PLS methods be used to build the models and then the weights and loadings of the individual blocks and super block and the percentage variation explained in each block be calculated from the results. (C) 1998 John Wiley & Sons, Ltd.},
   keywords = {hierarchical models
latent variables
multiblock models
pca
pls
partial least-squares
regression
prediction
diagnosis
quality},
   year = {1998}
}

@article{
   author = {Wilcoxen, Keith M. and Uehara, Taisuke and Myint, Khin Than and Sato, Yoshiaki and Oda, Yoshiya},
   title = {Practical metabolomics in drug discovery},
   journal = {Expert Opin. Drug Discovery},
   volume = {5},
   number = {3},
   pages = {249-263},
   note = {Copyright (C) 2012 American Chemical Society (ACS). All Rights Reserved.
CAPLUS AN 2010:257075(Journal; General Review)
10.1517/17460441003631854},
   abstract = {A review. Importance of the field: Metabolomics is increasingly becoming an important field in the pharmaceutical industry to support the discovery and development of therapeutic agents. Importance of the field: Metabolomics is increasingly becoming an important field in the pharmaceutical industry to support the discovery and development of therapeutic agents. It allows the comprehensive and simultaneous profiling of hundreds of discrete biol. important mols., including amino acids, sugars, lipids and exogenous substances from biol. fluids and tissues. Metabolomics is the omics' field that most represents the interplay of internal biol. regulation and external environmental influences on disease, thereby being of particular importance to disease mitigation and management. Areas covered in this review: Technol. advances in the exptl. work flow, anal. detection strategies and bioinformatics tools have enabled metabolomics studies to become increasingly comprehensive, robust and informative for the understanding of disease, drug action and the development of biomarkers. This review will focus on the practical aspects of metabolomics studies as they have been applied to the study of mammalian biol. systems, specifically targeted to the steps of exptl. design with regard to sample prepn., sample anal. and data anal. of both polar and non-polar metabolites. What the reader will gain: The reader will gain an overview of the field of metabolomics as it applies to drug development and the practical issues involved with exptl. design. We will discuss the various methods of sample prepn. and anal. as they apply to different classes of metabolites and highlight recent advances in the field that illustrate these methods. Take home message: The field of metabolomics is a rapidly expanding discipline that is being applied to various aspects of drug development. The large diversity of metabolites found in nature dictates that different methods be developed for the investigation of different classes of metabolites. As the field of metabolomics continues to mature, it is likely that it will play an increasingly important role in the characterization of disease and the future development of biomarkers to assess drug efficacy and safety. [on SciFinder(R)]},
   keywords = {review metabolomics drug discovery},
   year = {2010}
}

@article{
   author = {Wold, S. and Antti, H. and Lindgren, F. and Ohman, J.},
   title = {Orthogonal signal correction of near-infrared spectra},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {44},
   number = {1-2},
   pages = {175-185},
   note = {155LW
Times Cited:466
Cited References Count:13},
   abstract = {Near-infrared (NIR) spectra are often pre-processed in order to remove systematic noise such as base-line variation and multiplicative scatter effects. This is done by differentiating the spectra to first or second derivatives, by multiplicative signal correction (MSC), or by similar mathematical filtering methods. This pre-processing may, however, also remove information from the spectra regarding Y (the measured response variable in multivariate calibration applications). We here show how a variant of PLS can be used to achieve a signal correction that is as close to orthogonal as possible to a given Y-vector or Y-matrix. Thus, one ensures that the signal correction removes as little information as possible regarding Y. In the case when the number of X-variables (K) exceeds the number of observations (N), strict orthogonality is obtained. The approach is called orthogonal signal correction (OSC) and is here applied to four different data sets of multivariate calibration. The results are compared with those of traditional signal correction as well as with those of no pre-processing, and OSC is shown to give substantial improvements. Prediction sets of new data, not used in the model development, are used for the comparisons. (C) 1998 Elsevier Science B.V. All rights reserved.},
   keywords = {orthogonal signal correction
near-infrared spectra
multiplicative signal correction
regression-models
binding},
   year = {1998}
}

@inbook{
   author = {Wold, S. and Johansson, E. and Cocchi, M.},
   title = {PLS},
   booktitle = {3D-QSAR in Drug Design: Theory, Methods and Applications},
   editor = {Kubinyi, H.},
   publisher = {ESCOM Science},
   address = {Ledien},
   pages = {523-550},
   year = {1993}
}

@article{
   author = {Wold, S. and Sjostrom, M. and Eriksson, L.},
   title = {PLS-regression: a basic tool of chemometrics},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {58},
   number = {2},
   pages = {109-130},
   note = {495VJ
Times Cited:1123
Cited References Count:45},
   abstract = {PLS-regression (PLSR) is the PLS approach in its simplest, and in chemistry and technology, most used form (two-block predictive PLS). PLSR is a method for relating two data matrices, X and Y, by a linear multivariate model, but goes beyond traditional regression in that it models also the structure of X and Y. PLSR derives its usefulness from its ability to analyze data with many, noisy, collinear, and even incomplete variables in both X and Y. PLSR has the desirable property that the precision of the model parameters improves with the increasing number of relevant variables and observations.
This article reviews PLSR as it has developed to become a standard tool in chemometrics and used in chemistry and engineering. The underlying model and its assumptions are discussed, and commonly used diagnostics are reviewed together with the interpretation of resulting parameters.
Two examples are used as illustrations: First, a Quantitative Structure-Activity Relationship (QSAR)/Quantitative Structure-Property Relationship (QSPR) data set of peptides is used to outline how to develop, interpret and refine a PLSR model. Second, a data set from the manufacturing of recycled paper is analyzed to illustrate time series modelling of process data by means of PLSR and time-lagged X-variables. (C) 2001 Elsevier Science B.V. All rights reserved.},
   keywords = {pls
plsr
two-block predictive pls
latent variables
multivariate analysis
partial least-squares
cross-validation
kernel algorithm
amino-acids
prediction
jackknife
design},
   year = {2001}
}

@article{
   author = {Worley, Bradley  and Halouska, Steven  and Powers, Robert },
   title = {Utilities for Quantifying Separation in PCA/PLS-DA Scores Plots},
   journal = {Anal. Biochem. },
   volume = {submitted},
   year = {2012}
}

@article{
   author = {Wu, H. F. and Southam, A. D. and Hines, A. and Viant, M. R.},
   title = {High-throughput tissue extraction protocol for NMR- and MS-based metabolomics},
   journal = {Analytical Biochemistry},
   volume = {372},
   number = {2},
   pages = {204-212},
   note = {243NT
Times Cited:81
Cited References Count:33},
   abstract = {In metabolomics, tissues typically are extracted by grinding in liquid nitrogen followed by the stepwise addition of solvents. This is time-consuming and difficult to automate, and the multiple steps can introduce variability. Here we optimize tissue extraction methods compatible with high-throughput, reproducible nuclear magnetic resonance (NMR) spectroscopy- and mass spectrometry (MS)-based metabolomics. Previously, we concluded that methanol/chloroform/water extraction is preferable for metabolomics, and we further optimized this here using fish liver and an automated Precellys 24 bead-based homogenizer, allowing rapid extraction of multiple samples without carryover. We compared three solvent addition strategies: stepwise, two-step, and all solvents simultaneously. Then we evaluated strategies for improved partitioning of metabolites between solvent phases, including the addition of extra water and different partition times. Polar extracts were analyzed by NMR and principal components analysis, and the two-step approach was preferable based on lipid partitioning, reproducibility, yield, and throughput. Longer partitioning or extra water increased yield and decreased lipids in the polar phase but caused metabolic decay in these extracts. Overall, we conclude that the two-step method with extra water provides good quality data but that the two-step method with 10 min partitioning provides a more accurate snapshot of the metabolome. Finally, when validating the two-step strategy using NMR and MS metabolomics, we showed that technical variability was considerably smaller than biological variability. (C) 2007 Elsevier Inc. All rights reserved.},
   keywords = {metabolomics
tissue
metabolite
extraction
nmr
ms
ft-icr
liver
fish
spectrometry-based metabolomics
pattern-recognition
mass-spectrometry
quantitative-analysis
h-1-nmr spectroscopy
metabonomics
transformation
metabolites
accuracy
health},
   year = {2008}
}

@article{
   author = {Wu, W. and Daszykowski, M. and Walczak, B. and Sweatman, B. C. and Connor, S. C. and Haseldeo, J. N. and Crowther, D. J. and Gill, R. W. and Lutz, M. W.},
   title = {Peak alignment of urine NMR spectra using fuzzy warping},
   journal = {Journal of Chemical Information and Modeling},
   volume = {46},
   number = {2},
   pages = {863-875},
   note = {028XT
Times Cited:26
Cited References Count:31},
   abstract = {Proton nuclear magnetic resonance (H-1 NMR) spectroscopic analysis of mixtures has been used extensively for a variety of applications ranging from the analysis of plant extracts, wine, and food to the evaluation of toxicity in animals. For example, NMR analysis of urine samples has been used extensively for biomarker discovery and, more simply, for the construction of classification models of toxicity, disease, and biochemical phenotype. However, NMR spectra of complex mixtures typically show unwanted local peak shifts caused by matrix and instrument variability, which must be compensated for prior to statistical analysis and interpretation of the data. One approach is to align the spectral peaks across the data set. An efficient and fast warping algorithm is required as the signals typically contain ca. 32 000-64 000 data points and there can be several thousand spectra in a data set. As demonstrated in our study, the iterative fuzzy warping algorithm fulfills these requirements and can be used on-Line for an alignment of the NMR spectra. Correlation coefficients between the aligned and target spectra are used as the evaluation function for the algorithm, and its performance is compared with those of other published warping methods.},
   keywords = {kernel algorithm
metabonomics
pls
classification
regression
variables
h-1-nmr
signals},
   year = {2006}
}

@article{
   author = {Xia, J. M. and Wu, X. J. and Yuan, Y. J.},
   title = {Integration of wavelet transform with PCA and ANN for metabolomics data-mining},
   journal = {Metabolomics},
   volume = {3},
   number = {4},
   pages = {531-537},
   note = {231AL
Times Cited:6
Cited References Count:34},
   abstract = {PCA (principal components analysis) and ANN (artificial neural network) are two broadly used pattern recognition methods in metabolomics data-mining. Yet their limitations sometimes are great obstacles for researchers. In this paper the wavelet transform (WT) method was used to integrate with PCA and ANN to improve their performance in manipulating metabolomics data. A dataset was decomposed by wavelets and then reconstructed. The "hard thresholding'' algorithm was used, through which the detail information was discarded, and the entire "metabolomics image'' reconstructed on the significant information. It was supposed that the most relevant information was captured after this process. It was found that, thanks to its ability in denoising data, the WT method could significantly improve the performance of the non-linear essence-extracting method ANN in classifying samples; further integration of WT with PCA showed that WT could greatly enhance the ability of PCA in distinguishing one group of samples from another and also its ability in identifying potential biomarkers. The results highlighted WT as a promising resolution in bridging the gap between huge bytes of data and the instructive biological information.},
   keywords = {metabolomics
data-mining
pca
ann
wt
pattern-recognition
neural-network
metabonomics
systems
classification
biomarkers
toxicology
diagnosis
alignment
features},
   year = {2007}
}

@article{
   author = {Xu, Q. S. and Liang, Y. Z.},
   title = {Monte Carlo cross validation},
   journal = {Chemometrics and Intelligent Laboratory Systems},
   volume = {56},
   number = {1},
   pages = {1-11},
   note = {420HV
Times Cited:128
Cited References Count:25},
   abstract = {In order to choose correctly the dimension of calibration model in chemistry, a new simple and effective method named Monte Carlo cross validation (MCCV) is introduced in the present work. Unlike leave-one-out procedure commonly used in chemometrics for cross validation (CV), the Monte Carlo cross validation developed in this paper is an asymptotically consistent method in determining the number of components in calibration model. It can avoid an unnecessary large model and therefore decreases the risk of over-fitting for the calibration model. The results obtained from simulation study showed that MCCV has an obviously larger probability than leave-one-out CV in choosing the correct number of components that the model should contain. The results fi om real data sets demonstrated that MCCV could successfully choose the appropriate model, but leave-one-out CV could not. (C) 2001 Elsevier Science B.V. All rights reserved.},
   keywords = {model
number of components
leave-one-out
cross validation
monte carlo
prediction rule
model selection
error rate
regression
choice},
   year = {2001}
}

@article{
   author = {Xu, Q. S. and Liang, Y. Z. and Du, Y. P.},
   title = {Monte Carlo cross-validation for selecting a model and estimating the prediction error in multivariate calibration},
   journal = {Journal of Chemometrics},
   volume = {18},
   number = {2},
   pages = {112-120},
   note = {838AV
Times Cited:45
Cited References Count:43},
   abstract = {A new simple and effective method named Monte Carlo cross validation (MCCV) has been introduced and evaluated for selecting a model and estimating the prediction ability of the model selected. Unlike the leave-one-out procedure widely used in chemometrics for cross-validation (CV), the Monte Carlo cross-validation developed in this paper is an asymptotically consistent method of model selection. It can avoid an unnecessarily large model and therefore decreases the risk of overfitting of the model. The results obtained from a simulation study showed that MCCV has an obviously larger probability than leave-one-out CV (LOO-CV) of selecting the model with best prediction ability and that a corrected MCCV (CMCCV) could give a more accurate estimation of prediction ability than LOO-CV or MCCV. The results obtained with real data sets demonstrated that MCCV could successfully select an appropriate model and that CMCCV could assess the prediction ability of the selected model with satisfactory accuracy. Copyright (C) 2004 John Wiley Sons, Ltd.},
   keywords = {model selection
prediction error
cross-validation
partial least-squares
principal component regression
topological organic-chemistry
graph-theory
indexes
alkanes
choice
number},
   year = {2004}
}

@article{
   author = {Zhang, B. and Halouska, S. and Schiaffo, C. E. and Sadykov, M. R. and Somerville, G. A. and Powers, R.},
   title = {NMR Analysis of a Stress Response Metabolic Signaling Network},
   journal = {Journal of Proteome Research},
   volume = {10},
   number = {8},
   pages = {3743-3754},
   note = {802CW
Times Cited:0
Cited References Count:74},
   abstract = {We previously hypothesized that Staphylococcus epidermidis senses a diverse set of environmental and nutritional factors associated with biofilm formation through a modulation in the activity of the tricarboxylic acid (TCA) cycle. Herein, we report our further investigation of the impact of additional environmental stress factors on TCA cycle activity and provide a detailed description of our NMR methodology. S. epidermidis wild-type strain 1457 was treated with stressors that are associated with biofilm formation, a sublethal dose of tetracycline, 5% NaCl, 2% glucose, and autoinducer-2 (AI-2). As controls and to integrate our current data with our previous study, 4% ethanol stress and iron-limitation were also used. Consistent with our prior observations, the effect of many environmental stress factors on the S. epidermidis metabolome was essentially identical to the effect of TCA cycle inactivation in the aconitase mutant strain 1457-acnA::tetM. A detailed quantitative analysis of metabolite concentration changes using 2D H-1-C-13 HSQC and H-1-H-1 TOCSY spectra identified a network of 37 metabolites uniformly affected by the stressors and TCA cycle inactivation. We postulate that the TCA cycle acts as the central pathway in a metabolic signaling network.},
   keywords = {nmr
metabolomics
central metabolism
bioinformatics
stress response
polysaccharide intercellular adhesin
forming staphylococcus-epidermidis
biofilm formation
iron limitation
aureus
growth
virulence
identification
expression
infection},
   year = {2011}
}

@inproceedings{
   author = {Zhou, Wang and Seoung Bum, Kim},
   title = {Automatic Alignment of High-Resolution NMR Spectra Using a Bayesian Estimation Approach},
   booktitle = {18th International Conference on Pattern Recognition, 2006. ICPR 2006.},
   editor = {Werner, Robert},
   series = {ICPR 2006},
   year = {2006},
   publisher = {IEEE Computer Society},
   volume = {4},
   pages = {667-670},
   keywords = {Bayes methods
biomedical NMR
blood
diseases
medical signal processing
pattern recognition
spectral analysis
statistical analysis
Bayesian estimation
Bayesian statistical framework
additive noise
baseline intensity variation
disease state
high-resolution NMR spectral alignment
human plasma
metabolic change detection
metabolic change recognition
natural biological variation
nuclear magnetic resonance
physiological alteration
spectral shift},

}

